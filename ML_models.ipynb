{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":1032238,"sourceType":"datasetVersion","datasetId":568973},{"sourceId":10532147,"sourceType":"datasetVersion","datasetId":6517427},{"sourceId":10630237,"sourceType":"datasetVersion","datasetId":6581841}],"dockerImageVersionId":30839,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import pandas as pd\nimport time\ndf = pd.read_csv(\"/kaggle/input/gtzan-dataset-music-genre-classification/Data/features_30_sec.csv\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-16T02:48:46.393179Z","iopub.execute_input":"2025-02-16T02:48:46.393612Z","iopub.status.idle":"2025-02-16T02:48:46.425922Z","shell.execute_reply.started":"2025-02-16T02:48:46.393578Z","shell.execute_reply":"2025-02-16T02:48:46.424821Z"}},"outputs":[],"execution_count":9},{"cell_type":"code","source":"df.info()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-16T02:48:46.427560Z","iopub.execute_input":"2025-02-16T02:48:46.427959Z","iopub.status.idle":"2025-02-16T02:48:46.444427Z","shell.execute_reply.started":"2025-02-16T02:48:46.427917Z","shell.execute_reply":"2025-02-16T02:48:46.443306Z"}},"outputs":[{"name":"stdout","text":"<class 'pandas.core.frame.DataFrame'>\nRangeIndex: 1000 entries, 0 to 999\nData columns (total 60 columns):\n #   Column                   Non-Null Count  Dtype  \n---  ------                   --------------  -----  \n 0   filename                 1000 non-null   object \n 1   length                   1000 non-null   int64  \n 2   chroma_stft_mean         1000 non-null   float64\n 3   chroma_stft_var          1000 non-null   float64\n 4   rms_mean                 1000 non-null   float64\n 5   rms_var                  1000 non-null   float64\n 6   spectral_centroid_mean   1000 non-null   float64\n 7   spectral_centroid_var    1000 non-null   float64\n 8   spectral_bandwidth_mean  1000 non-null   float64\n 9   spectral_bandwidth_var   1000 non-null   float64\n 10  rolloff_mean             1000 non-null   float64\n 11  rolloff_var              1000 non-null   float64\n 12  zero_crossing_rate_mean  1000 non-null   float64\n 13  zero_crossing_rate_var   1000 non-null   float64\n 14  harmony_mean             1000 non-null   float64\n 15  harmony_var              1000 non-null   float64\n 16  perceptr_mean            1000 non-null   float64\n 17  perceptr_var             1000 non-null   float64\n 18  tempo                    1000 non-null   float64\n 19  mfcc1_mean               1000 non-null   float64\n 20  mfcc1_var                1000 non-null   float64\n 21  mfcc2_mean               1000 non-null   float64\n 22  mfcc2_var                1000 non-null   float64\n 23  mfcc3_mean               1000 non-null   float64\n 24  mfcc3_var                1000 non-null   float64\n 25  mfcc4_mean               1000 non-null   float64\n 26  mfcc4_var                1000 non-null   float64\n 27  mfcc5_mean               1000 non-null   float64\n 28  mfcc5_var                1000 non-null   float64\n 29  mfcc6_mean               1000 non-null   float64\n 30  mfcc6_var                1000 non-null   float64\n 31  mfcc7_mean               1000 non-null   float64\n 32  mfcc7_var                1000 non-null   float64\n 33  mfcc8_mean               1000 non-null   float64\n 34  mfcc8_var                1000 non-null   float64\n 35  mfcc9_mean               1000 non-null   float64\n 36  mfcc9_var                1000 non-null   float64\n 37  mfcc10_mean              1000 non-null   float64\n 38  mfcc10_var               1000 non-null   float64\n 39  mfcc11_mean              1000 non-null   float64\n 40  mfcc11_var               1000 non-null   float64\n 41  mfcc12_mean              1000 non-null   float64\n 42  mfcc12_var               1000 non-null   float64\n 43  mfcc13_mean              1000 non-null   float64\n 44  mfcc13_var               1000 non-null   float64\n 45  mfcc14_mean              1000 non-null   float64\n 46  mfcc14_var               1000 non-null   float64\n 47  mfcc15_mean              1000 non-null   float64\n 48  mfcc15_var               1000 non-null   float64\n 49  mfcc16_mean              1000 non-null   float64\n 50  mfcc16_var               1000 non-null   float64\n 51  mfcc17_mean              1000 non-null   float64\n 52  mfcc17_var               1000 non-null   float64\n 53  mfcc18_mean              1000 non-null   float64\n 54  mfcc18_var               1000 non-null   float64\n 55  mfcc19_mean              1000 non-null   float64\n 56  mfcc19_var               1000 non-null   float64\n 57  mfcc20_mean              1000 non-null   float64\n 58  mfcc20_var               1000 non-null   float64\n 59  label                    1000 non-null   object \ndtypes: float64(57), int64(1), object(2)\nmemory usage: 468.9+ KB\n","output_type":"stream"}],"execution_count":10},{"cell_type":"code","source":"df.drop(columns=['filename', 'length'], inplace=True)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-16T02:48:46.446353Z","iopub.execute_input":"2025-02-16T02:48:46.446741Z","iopub.status.idle":"2025-02-16T02:48:46.464390Z","shell.execute_reply.started":"2025-02-16T02:48:46.446710Z","shell.execute_reply":"2025-02-16T02:48:46.463316Z"}},"outputs":[],"execution_count":11},{"cell_type":"markdown","source":"we will first test only the mfcc coefs ","metadata":{}},{"cell_type":"code","source":"mfcc_df = df.drop(columns=[column for column in df.columns if \"mfcc\" not in column and column != 'label'])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-16T02:48:46.466220Z","iopub.execute_input":"2025-02-16T02:48:46.466598Z","iopub.status.idle":"2025-02-16T02:48:46.480812Z","shell.execute_reply.started":"2025-02-16T02:48:46.466571Z","shell.execute_reply":"2025-02-16T02:48:46.479757Z"}},"outputs":[],"execution_count":12},{"cell_type":"code","source":"mfcc_df.columns","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-16T02:48:46.481781Z","iopub.execute_input":"2025-02-16T02:48:46.482113Z","iopub.status.idle":"2025-02-16T02:48:46.495135Z","shell.execute_reply.started":"2025-02-16T02:48:46.482085Z","shell.execute_reply":"2025-02-16T02:48:46.493841Z"}},"outputs":[{"execution_count":13,"output_type":"execute_result","data":{"text/plain":"Index(['mfcc1_mean', 'mfcc1_var', 'mfcc2_mean', 'mfcc2_var', 'mfcc3_mean',\n       'mfcc3_var', 'mfcc4_mean', 'mfcc4_var', 'mfcc5_mean', 'mfcc5_var',\n       'mfcc6_mean', 'mfcc6_var', 'mfcc7_mean', 'mfcc7_var', 'mfcc8_mean',\n       'mfcc8_var', 'mfcc9_mean', 'mfcc9_var', 'mfcc10_mean', 'mfcc10_var',\n       'mfcc11_mean', 'mfcc11_var', 'mfcc12_mean', 'mfcc12_var', 'mfcc13_mean',\n       'mfcc13_var', 'mfcc14_mean', 'mfcc14_var', 'mfcc15_mean', 'mfcc15_var',\n       'mfcc16_mean', 'mfcc16_var', 'mfcc17_mean', 'mfcc17_var', 'mfcc18_mean',\n       'mfcc18_var', 'mfcc19_mean', 'mfcc19_var', 'mfcc20_mean', 'mfcc20_var',\n       'label'],\n      dtype='object')"},"metadata":{}}],"execution_count":13},{"cell_type":"code","source":"from scipy.stats import f_oneway\n\ncolumns = mfcc_df.drop(columns=['label']).columns\n\nfor column in columns:\n    \n\n# Example: ANOVA for 'rms_mean' across groups in 'label'\n    grouped_data = [group[column] for _, group in df.groupby(\"label\")]\n    anova_result = f_oneway(*grouped_data)\n    print(f\"{column} ANOVA F-statistic: {anova_result.statistic}, p-value: {anova_result.pvalue}\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-16T02:48:46.496386Z","iopub.execute_input":"2025-02-16T02:48:46.496762Z","iopub.status.idle":"2025-02-16T02:48:46.648267Z","shell.execute_reply.started":"2025-02-16T02:48:46.496733Z","shell.execute_reply":"2025-02-16T02:48:46.647081Z"}},"outputs":[{"name":"stdout","text":"mfcc1_mean ANOVA F-statistic: 130.37183542543974, p-value: 2.494661015032167e-161\nmfcc1_var ANOVA F-statistic: 21.51234828075879, p-value: 1.726329448644408e-33\nmfcc2_mean ANOVA F-statistic: 83.189909207364, p-value: 1.0539227277289052e-114\nmfcc2_var ANOVA F-statistic: 22.22706092522391, p-value: 1.296930574459949e-34\nmfcc3_mean ANOVA F-statistic: 39.99480612844631, p-value: 5.049210410470474e-61\nmfcc3_var ANOVA F-statistic: 24.10080254855272, p-value: 1.5431020296757826e-37\nmfcc4_mean ANOVA F-statistic: 83.86855465766176, p-value: 1.8877433855052627e-115\nmfcc4_var ANOVA F-statistic: 61.487769845073075, p-value: 2.3055523149141784e-89\nmfcc5_mean ANOVA F-statistic: 32.89918842047562, p-value: 7.940594643409526e-51\nmfcc5_var ANOVA F-statistic: 52.855234881086304, p-value: 2.0691428284015633e-78\nmfcc6_mean ANOVA F-statistic: 66.03812293703791, p-value: 6.326860348888946e-95\nmfcc6_var ANOVA F-statistic: 56.71708165371829, p-value: 2.231637274456634e-83\nmfcc7_mean ANOVA F-statistic: 43.21343234035172, p-value: 1.674034112627033e-65\nmfcc7_var ANOVA F-statistic: 52.54382072594274, p-value: 5.262947022406732e-78\nmfcc8_mean ANOVA F-statistic: 67.49611739469503, p-value: 1.1183574495095913e-96\nmfcc8_var ANOVA F-statistic: 34.20489654598395, p-value: 9.759369579884774e-53\nmfcc9_mean ANOVA F-statistic: 55.340635182431676, p-value: 1.277251295386609e-81\nmfcc9_var ANOVA F-statistic: 24.014419489734475, p-value: 2.101317471149581e-37\nmfcc10_mean ANOVA F-statistic: 41.4137106505366, p-value: 5.218754951395962e-63\nmfcc10_var ANOVA F-statistic: 25.67984447946172, p-value: 5.618654188885101e-40\nmfcc11_mean ANOVA F-statistic: 29.985317517013605, p-value: 1.6600000557816033e-46\nmfcc11_var ANOVA F-statistic: 22.72612572664577, p-value: 2.1416494124414786e-35\nmfcc12_mean ANOVA F-statistic: 48.72503442530284, p-value: 5.676378160872387e-73\nmfcc12_var ANOVA F-statistic: 25.454970176618055, p-value: 1.2459365496264449e-39\nmfcc13_mean ANOVA F-statistic: 50.61102834837972, p-value: 1.7958324330666836e-75\nmfcc13_var ANOVA F-statistic: 34.44971223313888, p-value: 4.29496707495941e-53\nmfcc14_mean ANOVA F-statistic: 24.096546587304772, p-value: 1.5667501431805019e-37\nmfcc14_var ANOVA F-statistic: 21.402469117099553, p-value: 2.5726480557454078e-33\nmfcc15_mean ANOVA F-statistic: 47.029669608481896, p-value: 1.0601140034844858e-70\nmfcc15_var ANOVA F-statistic: 17.167025503987468, p-value: 1.486977087568697e-26\nmfcc16_mean ANOVA F-statistic: 17.644524620124496, p-value: 2.5238766617875377e-27\nmfcc16_var ANOVA F-statistic: 19.456475310029607, p-value: 3.142214893079576e-30\nmfcc17_mean ANOVA F-statistic: 59.083651244112794, p-value: 2.285306707740541e-86\nmfcc17_var ANOVA F-statistic: 17.955469334876884, p-value: 7.971464776693531e-28\nmfcc18_mean ANOVA F-statistic: 11.267489424090563, p-value: 6.712865123354058e-17\nmfcc18_var ANOVA F-statistic: 22.084900139468374, p-value: 2.1684440204076645e-34\nmfcc19_mean ANOVA F-statistic: 22.607690649070992, p-value: 3.2821334200365857e-35\nmfcc19_var ANOVA F-statistic: 30.739908235923053, p-value: 1.2408566925353514e-47\nmfcc20_mean ANOVA F-statistic: 15.65100814919851, p-value: 4.267407949203671e-24\nmfcc20_var ANOVA F-statistic: 36.57438682736633, p-value: 3.6489325033538043e-56\n","output_type":"stream"}],"execution_count":14},{"cell_type":"code","source":"from sklearn.preprocessing import LabelEncoder\n\n# Assuming df['label'] contains the labels\ny = df['label']\n\n# Initialize the LabelEncoder\nencoder = LabelEncoder()\n\n# Fit and transform the labels\ny_encoded = encoder.fit_transform(y)\n\n# Map the numbers back to their original labels\nlabel_mapping = dict(zip(range(len(encoder.classes_)), encoder.classes_))\n\nprint(\"Encoded Labels:\")\nprint(label_mapping)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-16T02:48:46.649372Z","iopub.execute_input":"2025-02-16T02:48:46.649709Z","iopub.status.idle":"2025-02-16T02:48:46.656924Z","shell.execute_reply.started":"2025-02-16T02:48:46.649678Z","shell.execute_reply":"2025-02-16T02:48:46.655744Z"}},"outputs":[{"name":"stdout","text":"Encoded Labels:\n{0: 'blues', 1: 'classical', 2: 'country', 3: 'disco', 4: 'hiphop', 5: 'jazz', 6: 'metal', 7: 'pop', 8: 'reggae', 9: 'rock'}\n","output_type":"stream"}],"execution_count":15},{"cell_type":"code","source":"from sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import LabelEncoder, StandardScaler\nfrom sklearn.svm import SVC\nfrom sklearn.metrics import classification_report, confusion_matrix, roc_auc_score, RocCurveDisplay\nfrom bayes_opt import BayesianOptimization\nimport numpy as np\nimport matplotlib.pyplot as plt\n\n# Prétraitement des données\nX = mfcc_df.drop(columns=['label'])  # Supprimez les colonnes non pertinentes\ny = mfcc_df['label']\n\n# Encoder la variable cible\nencoder = LabelEncoder()\ny = encoder.fit_transform(y)\n\n# Normaliser les données\nscaler = StandardScaler()\nX_scaled = scaler.fit_transform(X)\n\n# Diviser les données en ensembles d'entraînement et de test\nX_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.2, random_state=42, stratify=y)\n\n# Fonction d'évaluation pour BayesianOptimization\ndef optimize_svm(C, gamma):\n    model = SVC(C=C, gamma=gamma, kernel='rbf', probability=True, random_state=42)\n    model.fit(X_train, y_train)\n    return model.score(X_test, y_test)\n\n# Définir les limites des hyperparamètres\nparam_bounds = {\n    'C': (0.1, 100),      # Paramètre de régularisation\n    'gamma': (1e-4, 1e-1) # Coefficient pour le noyau RBF\n}\n\n# Lancer l'optimisation\noptimizer = BayesianOptimization(f=optimize_svm, pbounds=param_bounds, random_state=42)\nstart_opt = time.time_ns()\noptimizer.maximize(init_points=5, n_iter=100)\nend_opt = time.time_ns()\nopt_time = (end_opt - start_opt) / 1e9  # Convert nanoseconds to seconds\n\nprint(f\"Hyperparameters tuning time: {opt_time:.3f} seconds\")\n\n\n# Extraire les meilleurs hyperparamètres\nbest_params = optimizer.max\nprint(\"Meilleurs hyperparamètres :\", best_params)\n\n# Entraîner le modèle avec les meilleurs hyperparamètres\nbest_model_30sec_mfcc_only = SVC(C=best_params['params']['C'], gamma=best_params['params']['gamma'], kernel='rbf', probability=True, random_state=42)\n# Training time\nstart_train = time.time_ns()\nbest_model_30sec_mfcc_only.fit(X_train, y_train)\nend_train = time.time_ns()\ntrain_time = (end_train - start_train) / 1e9  # Convert nanoseconds to seconds\nprint(f\"Training time: {train_time:.3f} seconds\")\n\n\n# Test (prediction) time\nstart_test = time.time_ns()\ny_pred = best_model_30sec_mfcc_only.predict(X_test)\nend_test = time.time_ns()\ntest_time = (end_test - start_test) / 1e9  # Convert nanoseconds to seconds\n\n\nprint(\"Rapport de classification :\\n\", classification_report(y_test, y_pred, target_names=encoder.classes_))\n\n# Matrice de confusion\nconf_matrix = confusion_matrix(y_test, y_pred)\nprint(\"Matrice de confusion :\\n\", conf_matrix)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-16T02:48:46.660085Z","iopub.execute_input":"2025-02-16T02:48:46.660430Z","iopub.status.idle":"2025-02-16T02:49:30.127906Z","shell.execute_reply.started":"2025-02-16T02:48:46.660402Z","shell.execute_reply":"2025-02-16T02:49:30.126802Z"}},"outputs":[{"name":"stdout","text":"|   iter    |  target   |     C     |   gamma   |\n-------------------------------------------------\n| \u001b[39m1        \u001b[39m | \u001b[39m0.67     \u001b[39m | \u001b[39m37.52    \u001b[39m | \u001b[39m0.09508  \u001b[39m |\n| \u001b[35m2        \u001b[39m | \u001b[35m0.71     \u001b[39m | \u001b[35m73.23    \u001b[39m | \u001b[35m0.05991  \u001b[39m |\n| \u001b[39m3        \u001b[39m | \u001b[39m0.69     \u001b[39m | \u001b[39m15.69    \u001b[39m | \u001b[39m0.01568  \u001b[39m |\n| \u001b[39m4        \u001b[39m | \u001b[39m0.685    \u001b[39m | \u001b[39m5.903    \u001b[39m | \u001b[39m0.08663  \u001b[39m |\n| \u001b[39m5        \u001b[39m | \u001b[39m0.705    \u001b[39m | \u001b[39m60.15    \u001b[39m | \u001b[39m0.07084  \u001b[39m |\n| \u001b[39m6        \u001b[39m | \u001b[39m0.69     \u001b[39m | \u001b[39m89.36    \u001b[39m | \u001b[39m0.08234  \u001b[39m |\n| \u001b[39m7        \u001b[39m | \u001b[39m0.69     \u001b[39m | \u001b[39m72.15    \u001b[39m | \u001b[39m0.08094  \u001b[39m |\n| \u001b[35m8        \u001b[39m | \u001b[35m0.725    \u001b[39m | \u001b[35m10.23    \u001b[39m | \u001b[35m0.05221  \u001b[39m |\n| \u001b[39m9        \u001b[39m | \u001b[39m0.69     \u001b[39m | \u001b[39m0.6638   \u001b[39m | \u001b[39m0.04643  \u001b[39m |\n| \u001b[39m10       \u001b[39m | \u001b[39m0.7      \u001b[39m | \u001b[39m66.79    \u001b[39m | \u001b[39m0.06425  \u001b[39m |\n| \u001b[39m11       \u001b[39m | \u001b[39m0.72     \u001b[39m | \u001b[39m73.23    \u001b[39m | \u001b[39m0.05736  \u001b[39m |\n| \u001b[39m12       \u001b[39m | \u001b[39m0.72     \u001b[39m | \u001b[39m73.22    \u001b[39m | \u001b[39m0.05165  \u001b[39m |\n| \u001b[35m13       \u001b[39m | \u001b[35m0.745    \u001b[39m | \u001b[35m1.96     \u001b[39m | \u001b[35m0.04389  \u001b[39m |\n| \u001b[39m14       \u001b[39m | \u001b[39m0.735    \u001b[39m | \u001b[39m1.971    \u001b[39m | \u001b[39m0.03947  \u001b[39m |\n| \u001b[39m15       \u001b[39m | \u001b[39m0.685    \u001b[39m | \u001b[39m69.05    \u001b[39m | \u001b[39m0.01233  \u001b[39m |\n| \u001b[39m16       \u001b[39m | \u001b[39m0.74     \u001b[39m | \u001b[39m1.956    \u001b[39m | \u001b[39m0.05938  \u001b[39m |\n| \u001b[39m17       \u001b[39m | \u001b[39m0.74     \u001b[39m | \u001b[39m1.969    \u001b[39m | \u001b[39m0.05439  \u001b[39m |\n| \u001b[39m18       \u001b[39m | \u001b[39m0.715    \u001b[39m | \u001b[39m73.24    \u001b[39m | \u001b[39m0.04501  \u001b[39m |\n| \u001b[39m19       \u001b[39m | \u001b[39m0.705    \u001b[39m | \u001b[39m11.59    \u001b[39m | \u001b[39m0.01993  \u001b[39m |\n| \u001b[39m20       \u001b[39m | \u001b[39m0.705    \u001b[39m | \u001b[39m1.967    \u001b[39m | \u001b[39m0.08782  \u001b[39m |\n| \u001b[35m21       \u001b[39m | \u001b[35m0.75     \u001b[39m | \u001b[35m1.936    \u001b[39m | \u001b[35m0.04856  \u001b[39m |\n| \u001b[39m22       \u001b[39m | \u001b[39m0.735    \u001b[39m | \u001b[39m1.931    \u001b[39m | \u001b[39m0.0401   \u001b[39m |\n| \u001b[39m23       \u001b[39m | \u001b[39m0.695    \u001b[39m | \u001b[39m81.94    \u001b[39m | \u001b[39m0.06811  \u001b[39m |\n| \u001b[39m24       \u001b[39m | \u001b[39m0.7      \u001b[39m | \u001b[39m50.26    \u001b[39m | \u001b[39m0.06722  \u001b[39m |\n| \u001b[39m25       \u001b[39m | \u001b[39m0.735    \u001b[39m | \u001b[39m1.931    \u001b[39m | \u001b[39m0.06208  \u001b[39m |\n| \u001b[35m26       \u001b[39m | \u001b[35m0.755    \u001b[39m | \u001b[35m1.909    \u001b[39m | \u001b[35m0.04919  \u001b[39m |\n| \u001b[39m27       \u001b[39m | \u001b[39m0.72     \u001b[39m | \u001b[39m1.911    \u001b[39m | \u001b[39m0.07041  \u001b[39m |\n| \u001b[39m28       \u001b[39m | \u001b[39m0.7      \u001b[39m | \u001b[39m1.951    \u001b[39m | \u001b[39m0.02288  \u001b[39m |\n| \u001b[39m29       \u001b[39m | \u001b[39m0.685    \u001b[39m | \u001b[39m64.84    \u001b[39m | \u001b[39m0.01181  \u001b[39m |\n| \u001b[39m30       \u001b[39m | \u001b[39m0.745    \u001b[39m | \u001b[39m1.916    \u001b[39m | \u001b[39m0.04232  \u001b[39m |\n| \u001b[39m31       \u001b[39m | \u001b[39m0.695    \u001b[39m | \u001b[39m46.57    \u001b[39m | \u001b[39m0.0776   \u001b[39m |\n| \u001b[39m32       \u001b[39m | \u001b[39m0.69     \u001b[39m | \u001b[39m36.35    \u001b[39m | \u001b[39m0.006665 \u001b[39m |\n| \u001b[39m33       \u001b[39m | \u001b[39m0.695    \u001b[39m | \u001b[39m81.8     \u001b[39m | \u001b[39m0.02166  \u001b[39m |\n| \u001b[39m34       \u001b[39m | \u001b[39m0.69     \u001b[39m | \u001b[39m92.01    \u001b[39m | \u001b[39m0.07994  \u001b[39m |\n| \u001b[39m35       \u001b[39m | \u001b[39m0.695    \u001b[39m | \u001b[39m79.02    \u001b[39m | \u001b[39m0.007546 \u001b[39m |\n| \u001b[39m36       \u001b[39m | \u001b[39m0.74     \u001b[39m | \u001b[39m1.883    \u001b[39m | \u001b[39m0.04254  \u001b[39m |\n| \u001b[39m37       \u001b[39m | \u001b[39m0.655    \u001b[39m | \u001b[39m1.877    \u001b[39m | \u001b[39m0.01248  \u001b[39m |\n| \u001b[39m38       \u001b[39m | \u001b[39m0.73     \u001b[39m | \u001b[39m73.22    \u001b[39m | \u001b[39m0.0492   \u001b[39m |\n| \u001b[39m39       \u001b[39m | \u001b[39m0.75     \u001b[39m | \u001b[39m1.892    \u001b[39m | \u001b[39m0.04748  \u001b[39m |\n| \u001b[39m40       \u001b[39m | \u001b[39m0.72     \u001b[39m | \u001b[39m15.05    \u001b[39m | \u001b[39m0.04515  \u001b[39m |\n| \u001b[39m41       \u001b[39m | \u001b[39m0.735    \u001b[39m | \u001b[39m1.88     \u001b[39m | \u001b[39m0.06243  \u001b[39m |\n| \u001b[39m42       \u001b[39m | \u001b[39m0.675    \u001b[39m | \u001b[39m88.55    \u001b[39m | \u001b[39m0.01509  \u001b[39m |\n| \u001b[39m43       \u001b[39m | \u001b[39m0.695    \u001b[39m | \u001b[39m62.4     \u001b[39m | \u001b[39m0.03079  \u001b[39m |\n| \u001b[39m44       \u001b[39m | \u001b[39m0.73     \u001b[39m | \u001b[39m99.91    \u001b[39m | \u001b[39m0.04861  \u001b[39m |\n| \u001b[39m45       \u001b[39m | \u001b[39m0.695    \u001b[39m | \u001b[39m85.98    \u001b[39m | \u001b[39m0.0243   \u001b[39m |\n| \u001b[39m46       \u001b[39m | \u001b[39m0.755    \u001b[39m | \u001b[39m1.892    \u001b[39m | \u001b[39m0.0485   \u001b[39m |\n| \u001b[39m47       \u001b[39m | \u001b[39m0.695    \u001b[39m | \u001b[39m73.21    \u001b[39m | \u001b[39m0.03074  \u001b[39m |\n| \u001b[39m48       \u001b[39m | \u001b[39m0.72     \u001b[39m | \u001b[39m99.89    \u001b[39m | \u001b[39m0.05226  \u001b[39m |\n| \u001b[39m49       \u001b[39m | \u001b[39m0.695    \u001b[39m | \u001b[39m99.93    \u001b[39m | \u001b[39m0.02354  \u001b[39m |\n| \u001b[39m50       \u001b[39m | \u001b[39m0.735    \u001b[39m | \u001b[39m1.947    \u001b[39m | \u001b[39m0.05236  \u001b[39m |\n| \u001b[39m51       \u001b[39m | \u001b[39m0.68     \u001b[39m | \u001b[39m11.86    \u001b[39m | \u001b[39m0.08962  \u001b[39m |\n| \u001b[39m52       \u001b[39m | \u001b[39m0.7      \u001b[39m | \u001b[39m99.91    \u001b[39m | \u001b[39m0.06296  \u001b[39m |\n| \u001b[39m53       \u001b[39m | \u001b[39m0.68     \u001b[39m | \u001b[39m13.65    \u001b[39m | \u001b[39m0.08892  \u001b[39m |\n| \u001b[39m54       \u001b[39m | \u001b[39m0.745    \u001b[39m | \u001b[39m1.868    \u001b[39m | \u001b[39m0.05321  \u001b[39m |\n| \u001b[39m55       \u001b[39m | \u001b[39m0.74     \u001b[39m | \u001b[39m1.91     \u001b[39m | \u001b[39m0.05832  \u001b[39m |\n| \u001b[39m56       \u001b[39m | \u001b[39m0.665    \u001b[39m | \u001b[39m38.58    \u001b[39m | \u001b[39m0.09954  \u001b[39m |\n| \u001b[39m57       \u001b[39m | \u001b[39m0.72     \u001b[39m | \u001b[39m62.62    \u001b[39m | \u001b[39m0.05031  \u001b[39m |\n| \u001b[39m58       \u001b[39m | \u001b[39m0.73     \u001b[39m | \u001b[39m1.895    \u001b[39m | \u001b[39m0.0649   \u001b[39m |\n| \u001b[39m59       \u001b[39m | \u001b[39m0.69     \u001b[39m | \u001b[39m88.63    \u001b[39m | \u001b[39m0.00795  \u001b[39m |\n| \u001b[39m60       \u001b[39m | \u001b[39m0.695    \u001b[39m | \u001b[39m99.9     \u001b[39m | \u001b[39m0.03076  \u001b[39m |\n| \u001b[39m61       \u001b[39m | \u001b[39m0.74     \u001b[39m | \u001b[39m1.848    \u001b[39m | \u001b[39m0.03977  \u001b[39m |\n| \u001b[39m62       \u001b[39m | \u001b[39m0.74     \u001b[39m | \u001b[39m1.828    \u001b[39m | \u001b[39m0.04005  \u001b[39m |\n| \u001b[39m63       \u001b[39m | \u001b[39m0.745    \u001b[39m | \u001b[39m1.883    \u001b[39m | \u001b[39m0.05556  \u001b[39m |\n| \u001b[39m64       \u001b[39m | \u001b[39m0.705    \u001b[39m | \u001b[39m1.834    \u001b[39m | \u001b[39m0.0253   \u001b[39m |\n| \u001b[39m65       \u001b[39m | \u001b[39m0.72     \u001b[39m | \u001b[39m15.3     \u001b[39m | \u001b[39m0.05494  \u001b[39m |\n| \u001b[39m66       \u001b[39m | \u001b[39m0.74     \u001b[39m | \u001b[39m1.805    \u001b[39m | \u001b[39m0.0438   \u001b[39m |\n| \u001b[39m67       \u001b[39m | \u001b[39m0.74     \u001b[39m | \u001b[39m1.837    \u001b[39m | \u001b[39m0.05846  \u001b[39m |\n| \u001b[39m68       \u001b[39m | \u001b[39m0.72     \u001b[39m | \u001b[39m1.788    \u001b[39m | \u001b[39m0.06851  \u001b[39m |\n| \u001b[39m69       \u001b[39m | \u001b[39m0.745    \u001b[39m | \u001b[39m1.824    \u001b[39m | \u001b[39m0.05181  \u001b[39m |\n| \u001b[39m70       \u001b[39m | \u001b[39m0.72     \u001b[39m | \u001b[39m1.859    \u001b[39m | \u001b[39m0.07212  \u001b[39m |\n| \u001b[39m71       \u001b[39m | \u001b[39m0.74     \u001b[39m | \u001b[39m1.782    \u001b[39m | \u001b[39m0.03533  \u001b[39m |\n| \u001b[39m72       \u001b[39m | \u001b[39m0.685    \u001b[39m | \u001b[39m1.789    \u001b[39m | \u001b[39m0.01924  \u001b[39m |\n| \u001b[39m73       \u001b[39m | \u001b[39m0.72     \u001b[39m | \u001b[39m1.821    \u001b[39m | \u001b[39m0.07506  \u001b[39m |\n| \u001b[39m74       \u001b[39m | \u001b[39m0.74     \u001b[39m | \u001b[39m1.993    \u001b[39m | \u001b[39m0.04964  \u001b[39m |\n| \u001b[39m75       \u001b[39m | \u001b[39m0.72     \u001b[39m | \u001b[39m40.35    \u001b[39m | \u001b[39m0.0528   \u001b[39m |\n| \u001b[39m76       \u001b[39m | \u001b[39m0.745    \u001b[39m | \u001b[39m1.927    \u001b[39m | \u001b[39m0.04976  \u001b[39m |\n| \u001b[39m77       \u001b[39m | \u001b[39m0.71     \u001b[39m | \u001b[39m1.757    \u001b[39m | \u001b[39m0.02836  \u001b[39m |\n| \u001b[39m78       \u001b[39m | \u001b[39m0.735    \u001b[39m | \u001b[39m2.006    \u001b[39m | \u001b[39m0.05806  \u001b[39m |\n| \u001b[39m79       \u001b[39m | \u001b[39m0.67     \u001b[39m | \u001b[39m53.92    \u001b[39m | \u001b[39m0.09491  \u001b[39m |\n| \u001b[39m80       \u001b[39m | \u001b[39m0.74     \u001b[39m | \u001b[39m1.772    \u001b[39m | \u001b[39m0.04303  \u001b[39m |\n| \u001b[39m81       \u001b[39m | \u001b[39m0.735    \u001b[39m | \u001b[39m1.758    \u001b[39m | \u001b[39m0.06273  \u001b[39m |\n| \u001b[39m82       \u001b[39m | \u001b[39m0.715    \u001b[39m | \u001b[39m1.996    \u001b[39m | \u001b[39m0.07435  \u001b[39m |\n| \u001b[39m83       \u001b[39m | \u001b[39m0.68     \u001b[39m | \u001b[39m41.29    \u001b[39m | \u001b[39m0.01576  \u001b[39m |\n| \u001b[39m84       \u001b[39m | \u001b[39m0.7      \u001b[39m | \u001b[39m32.29    \u001b[39m | \u001b[39m0.06467  \u001b[39m |\n| \u001b[39m85       \u001b[39m | \u001b[39m0.735    \u001b[39m | \u001b[39m1.739    \u001b[39m | \u001b[39m0.06736  \u001b[39m |\n| \u001b[39m86       \u001b[39m | \u001b[39m0.745    \u001b[39m | \u001b[39m1.809    \u001b[39m | \u001b[39m0.05997  \u001b[39m |\n| \u001b[39m87       \u001b[39m | \u001b[39m0.74     \u001b[39m | \u001b[39m1.997    \u001b[39m | \u001b[39m0.03542  \u001b[39m |\n| \u001b[39m88       \u001b[39m | \u001b[39m0.735    \u001b[39m | \u001b[39m2.027    \u001b[39m | \u001b[39m0.03994  \u001b[39m |\n| \u001b[39m89       \u001b[39m | \u001b[39m0.68     \u001b[39m | \u001b[39m2.004    \u001b[39m | \u001b[39m0.01543  \u001b[39m |\n| \u001b[39m90       \u001b[39m | \u001b[39m0.735    \u001b[39m | \u001b[39m2.039    \u001b[39m | \u001b[39m0.05791  \u001b[39m |\n| \u001b[39m91       \u001b[39m | \u001b[39m0.72     \u001b[39m | \u001b[39m1.743    \u001b[39m | \u001b[39m0.08584  \u001b[39m |\n| \u001b[39m92       \u001b[39m | \u001b[39m0.72     \u001b[39m | \u001b[39m63.2     \u001b[39m | \u001b[39m0.05247  \u001b[39m |\n| \u001b[39m93       \u001b[39m | \u001b[39m0.7      \u001b[39m | \u001b[39m2.05     \u001b[39m | \u001b[39m0.02355  \u001b[39m |\n| \u001b[39m94       \u001b[39m | \u001b[39m0.745    \u001b[39m | \u001b[39m1.711    \u001b[39m | \u001b[39m0.05696  \u001b[39m |\n| \u001b[39m95       \u001b[39m | \u001b[39m0.735    \u001b[39m | \u001b[39m2.061    \u001b[39m | \u001b[39m0.06394  \u001b[39m |\n| \u001b[39m96       \u001b[39m | \u001b[39m0.725    \u001b[39m | \u001b[39m1.7      \u001b[39m | \u001b[39m0.06908  \u001b[39m |\n| \u001b[39m97       \u001b[39m | \u001b[39m0.725    \u001b[39m | \u001b[39m1.717    \u001b[39m | \u001b[39m0.06931  \u001b[39m |\n| \u001b[39m98       \u001b[39m | \u001b[39m0.63     \u001b[39m | \u001b[39m84.75    \u001b[39m | \u001b[39m0.0002544\u001b[39m |\n| \u001b[39m99       \u001b[39m | \u001b[39m0.74     \u001b[39m | \u001b[39m1.713    \u001b[39m | \u001b[39m0.03833  \u001b[39m |\n| \u001b[39m100      \u001b[39m | \u001b[39m0.75     \u001b[39m | \u001b[39m1.728    \u001b[39m | \u001b[39m0.05065  \u001b[39m |\n| \u001b[39m101      \u001b[39m | \u001b[39m0.745    \u001b[39m | \u001b[39m1.688    \u001b[39m | \u001b[39m0.04946  \u001b[39m |\n| \u001b[39m102      \u001b[39m | \u001b[39m0.685    \u001b[39m | \u001b[39m1.695    \u001b[39m | \u001b[39m0.01601  \u001b[39m |\n| \u001b[39m103      \u001b[39m | \u001b[39m0.74     \u001b[39m | \u001b[39m1.699    \u001b[39m | \u001b[39m0.04902  \u001b[39m |\n| \u001b[39m104      \u001b[39m | \u001b[39m0.75     \u001b[39m | \u001b[39m1.791    \u001b[39m | \u001b[39m0.04813  \u001b[39m |\n| \u001b[39m105      \u001b[39m | \u001b[39m0.68     \u001b[39m | \u001b[39m84.39    \u001b[39m | \u001b[39m0.01719  \u001b[39m |\n=================================================\nHyperparameters tuning time: 43.112 seconds\nMeilleurs hyperparamètres : {'target': 0.755, 'params': {'C': 1.9089914466354514, 'gamma': 0.04918797426292605}}\nTraining time: 0.308 seconds\nRapport de classification :\n               precision    recall  f1-score   support\n\n       blues       0.79      0.75      0.77        20\n   classical       0.73      0.95      0.83        20\n     country       0.76      0.80      0.78        20\n       disco       0.69      0.55      0.61        20\n      hiphop       0.74      0.85      0.79        20\n        jazz       0.80      0.80      0.80        20\n       metal       0.94      0.80      0.86        20\n         pop       0.83      0.75      0.79        20\n      reggae       0.67      0.70      0.68        20\n        rock       0.63      0.60      0.62        20\n\n    accuracy                           0.76       200\n   macro avg       0.76      0.76      0.75       200\nweighted avg       0.76      0.76      0.75       200\n\nMatrice de confusion :\n [[15  0  2  0  0  1  0  0  1  1]\n [ 0 19  0  0  0  1  0  0  0  0]\n [ 1  0 16  0  0  0  0  0  1  2]\n [ 0  1  0 11  3  0  0  3  1  1]\n [ 0  0  0  1 17  0  0  0  2  0]\n [ 1  2  0  0  0 16  0  0  0  1]\n [ 2  1  0  1  0  0 16  0  0  0]\n [ 0  2  0  1  1  0  0 15  1  0]\n [ 0  1  0  1  2  0  0  0 14  2]\n [ 0  0  3  1  0  2  1  0  1 12]]\n","output_type":"stream"}],"execution_count":16},{"cell_type":"code","source":"from scipy.stats import f_oneway\n\ncoeff_df = df.drop(columns=[column for column in df.columns if \"mfcc\" in column or column == 'label'])\ncolumns = coeff_df.columns\n\nfor column in columns:\n    \n\n# Example: ANOVA for 'rms_mean' across groups in 'label'\n    grouped_data = [group[column] for _, group in df.groupby(\"label\")]\n    anova_result = f_oneway(*grouped_data)\n    print(f\"{column} ANOVA F-statistic: {anova_result.statistic}, p-value: {anova_result.pvalue}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-16T02:49:30.129349Z","iopub.execute_input":"2025-02-16T02:49:30.129750Z","iopub.status.idle":"2025-02-16T02:49:30.192020Z","shell.execute_reply.started":"2025-02-16T02:49:30.129705Z","shell.execute_reply":"2025-02-16T02:49:30.190924Z"}},"outputs":[{"name":"stdout","text":"chroma_stft_mean ANOVA F-statistic: 176.45328235861118, p-value: 7.683149829866094e-199\nchroma_stft_var ANOVA F-statistic: 64.10383258045962, p-value: 1.4065551452115682e-92\nrms_mean ANOVA F-statistic: 74.19465163447585, p-value: 1.4859670070126082e-104\nrms_var ANOVA F-statistic: 68.27643848679423, p-value: 1.3070953105914825e-97\nspectral_centroid_mean ANOVA F-statistic: 97.48492445375801, p-value: 6.437171334336293e-130\nspectral_centroid_var ANOVA F-statistic: 82.13464835310555, p-value: 1.5461880467784952e-113\nspectral_bandwidth_mean ANOVA F-statistic: 116.60187897974004, p-value: 9.98275171430298e-149\nspectral_bandwidth_var ANOVA F-statistic: 29.580172163778805, p-value: 6.7154684261443235e-46\nrolloff_mean ANOVA F-statistic: 110.8713172445283, p-value: 2.9390324749054825e-143\nrolloff_var ANOVA F-statistic: 52.06524490427322, p-value: 2.2169019491470272e-77\nzero_crossing_rate_mean ANOVA F-statistic: 58.716379580769285, p-value: 6.611053380870471e-86\nzero_crossing_rate_var ANOVA F-statistic: 62.33300429220474, p-value: 2.0845028025642724e-90\nharmony_mean ANOVA F-statistic: 2.6799130848465955, p-value: 0.0044392046700439895\nharmony_var ANOVA F-statistic: 30.9138167462437, p-value: 6.837252552237365e-48\nperceptr_mean ANOVA F-statistic: 8.134104455975136, p-value: 1.025649555259675e-11\nperceptr_var ANOVA F-statistic: 80.38871167060972, p-value: 1.3582909070350427e-111\ntempo ANOVA F-statistic: 5.5142139248102335, p-value: 1.9771609789768624e-07\n","output_type":"stream"}],"execution_count":17},{"cell_type":"code","source":"from sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import LabelEncoder, StandardScaler\nfrom sklearn.svm import SVC\nfrom sklearn.metrics import classification_report, confusion_matrix, roc_auc_score, RocCurveDisplay\nfrom bayes_opt import BayesianOptimization\nimport numpy as np\nimport matplotlib.pyplot as plt\n\n# Prétraitement des données\nX = df.drop(columns=['label'])  # Supprimez les colonnes non pertinentes\ny = df['label']\n\n# Encoder la variable cible\nencoder = LabelEncoder()\ny = encoder.fit_transform(y)\n\n# Normaliser les données\nscaler = StandardScaler()\nX_scaled = scaler.fit_transform(X)\n\n# Diviser les données en ensembles d'entraînement et de test\nX_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.2, random_state=42, stratify=y)\n\n# Fonction d'évaluation pour BayesianOptimization\ndef optimize_svm(C, gamma):\n    model = SVC(C=C, gamma=gamma, kernel='rbf', probability=True, random_state=42)\n    model.fit(X_train, y_train)\n    return model.score(X_test, y_test)\n\n# Définir les limites des hyperparamètres\nparam_bounds = {\n    'C': (0.1, 100),      # Paramètre de régularisation\n    'gamma': (1e-4, 1e-1) # Coefficient pour le noyau RBF\n}\n\n# Lancer l'optimisation\noptimizer = BayesianOptimization(f=optimize_svm, pbounds=param_bounds, random_state=42)\nstart_opt = time.time_ns()\noptimizer.maximize(init_points=5, n_iter=100)\nend_opt = time.time_ns()\nopt_time = (end_opt - start_opt) / 1e9  # Convert nanoseconds to seconds\n\nprint(f\"Hyperparameters tuning time: {opt_time:.3f} seconds\")\n\n\n# Extraire les meilleurs hyperparamètres\nbest_params = optimizer.max\nprint(\"Meilleurs hyperparamètres :\", best_params)\n\n# Entraîner le modèle avec les meilleurs hyperparamètres\nbest_model_30sec = SVC(C=best_params['params']['C'], gamma=best_params['params']['gamma'], kernel='rbf', probability=True, random_state=42)\n# Training time\nstart_train = time.time_ns()\nbest_model_30sec.fit(X_train, y_train)\nend_train = time.time_ns()\ntrain_time = (end_train - start_train) / 1e9  # Convert nanoseconds to seconds\nprint(f\"Training time: {train_time:.3f} seconds\")\n\n\n# Test (prediction) time\nstart_test = time.time_ns()\ny_pred = best_model_30sec.predict(X_test)\nend_test = time.time_ns()\ntest_time = (end_test - start_test) / 1e9  # Convert nanoseconds to seconds\nprint(f\"Test (prediction) time: {test_time:.3f} seconds\")\n\n\nprint(\"Rapport de classification :\\n\", classification_report(y_test, y_pred, target_names=encoder.classes_))\n\n# Matrice de confusion\nconf_matrix = confusion_matrix(y_test, y_pred)\nprint(\"Matrice de confusion :\\n\", conf_matrix)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-16T02:49:30.193020Z","iopub.execute_input":"2025-02-16T02:49:30.193303Z","iopub.status.idle":"2025-02-16T02:50:12.492294Z","shell.execute_reply.started":"2025-02-16T02:49:30.193275Z","shell.execute_reply":"2025-02-16T02:50:12.490723Z"}},"outputs":[{"name":"stdout","text":"|   iter    |  target   |     C     |   gamma   |\n-------------------------------------------------\n| \u001b[39m1        \u001b[39m | \u001b[39m0.69     \u001b[39m | \u001b[39m37.52    \u001b[39m | \u001b[39m0.09508  \u001b[39m |\n| \u001b[35m2        \u001b[39m | \u001b[35m0.735    \u001b[39m | \u001b[35m73.23    \u001b[39m | \u001b[35m0.05991  \u001b[39m |\n| \u001b[35m3        \u001b[39m | \u001b[35m0.765    \u001b[39m | \u001b[35m15.69    \u001b[39m | \u001b[35m0.01568  \u001b[39m |\n| \u001b[39m4        \u001b[39m | \u001b[39m0.715    \u001b[39m | \u001b[39m5.903    \u001b[39m | \u001b[39m0.08663  \u001b[39m |\n| \u001b[39m5        \u001b[39m | \u001b[39m0.73     \u001b[39m | \u001b[39m60.15    \u001b[39m | \u001b[39m0.07084  \u001b[39m |\n| \u001b[39m6        \u001b[39m | \u001b[39m0.73     \u001b[39m | \u001b[39m15.7     \u001b[39m | \u001b[39m0.07163  \u001b[39m |\n| \u001b[39m7        \u001b[39m | \u001b[39m0.76     \u001b[39m | \u001b[39m15.67    \u001b[39m | \u001b[39m0.02114  \u001b[39m |\n| \u001b[39m8        \u001b[39m | \u001b[39m0.73     \u001b[39m | \u001b[39m10.23    \u001b[39m | \u001b[39m0.05221  \u001b[39m |\n| \u001b[39m9        \u001b[39m | \u001b[39m0.765    \u001b[39m | \u001b[39m15.77    \u001b[39m | \u001b[39m0.0142   \u001b[39m |\n| \u001b[39m10       \u001b[39m | \u001b[39m0.735    \u001b[39m | \u001b[39m15.85    \u001b[39m | \u001b[39m0.002221 \u001b[39m |\n| \u001b[39m11       \u001b[39m | \u001b[39m0.765    \u001b[39m | \u001b[39m15.7     \u001b[39m | \u001b[39m0.01567  \u001b[39m |\n| \u001b[39m12       \u001b[39m | \u001b[39m0.76     \u001b[39m | \u001b[39m15.76    \u001b[39m | \u001b[39m0.02105  \u001b[39m |\n| \u001b[35m13       \u001b[39m | \u001b[35m0.77     \u001b[39m | \u001b[35m15.45    \u001b[39m | \u001b[35m0.01376  \u001b[39m |\n| \u001b[39m14       \u001b[39m | \u001b[39m0.755    \u001b[39m | \u001b[39m15.36    \u001b[39m | \u001b[39m0.03664  \u001b[39m |\n| \u001b[39m15       \u001b[39m | \u001b[39m0.68     \u001b[39m | \u001b[39m15.48    \u001b[39m | \u001b[39m0.09796  \u001b[39m |\n| \u001b[39m16       \u001b[39m | \u001b[39m0.77     \u001b[39m | \u001b[39m15.7     \u001b[39m | \u001b[39m0.01648  \u001b[39m |\n| \u001b[39m17       \u001b[39m | \u001b[39m0.755    \u001b[39m | \u001b[39m15.7     \u001b[39m | \u001b[39m0.03659  \u001b[39m |\n| \u001b[39m18       \u001b[39m | \u001b[39m0.71     \u001b[39m | \u001b[39m15.44    \u001b[39m | \u001b[39m0.001256 \u001b[39m |\n| \u001b[39m19       \u001b[39m | \u001b[39m0.765    \u001b[39m | \u001b[39m11.59    \u001b[39m | \u001b[39m0.01993  \u001b[39m |\n| \u001b[39m20       \u001b[39m | \u001b[39m0.755    \u001b[39m | \u001b[39m15.45    \u001b[39m | \u001b[39m0.03501  \u001b[39m |\n| \u001b[39m21       \u001b[39m | \u001b[39m0.755    \u001b[39m | \u001b[39m11.57    \u001b[39m | \u001b[39m0.03078  \u001b[39m |\n| \u001b[39m22       \u001b[39m | \u001b[39m0.755    \u001b[39m | \u001b[39m15.46    \u001b[39m | \u001b[39m0.03071  \u001b[39m |\n| \u001b[39m23       \u001b[39m | \u001b[39m0.73     \u001b[39m | \u001b[39m81.94    \u001b[39m | \u001b[39m0.06811  \u001b[39m |\n| \u001b[39m24       \u001b[39m | \u001b[39m0.77     \u001b[39m | \u001b[39m11.61    \u001b[39m | \u001b[39m0.01593  \u001b[39m |\n| \u001b[39m25       \u001b[39m | \u001b[39m0.75     \u001b[39m | \u001b[39m11.62    \u001b[39m | \u001b[39m0.02806  \u001b[39m |\n| \u001b[39m26       \u001b[39m | \u001b[39m0.755    \u001b[39m | \u001b[39m11.6     \u001b[39m | \u001b[39m0.03023  \u001b[39m |\n| \u001b[39m27       \u001b[39m | \u001b[39m0.755    \u001b[39m | \u001b[39m15.78    \u001b[39m | \u001b[39m0.03076  \u001b[39m |\n| \u001b[39m28       \u001b[39m | \u001b[39m0.745    \u001b[39m | \u001b[39m15.76    \u001b[39m | \u001b[39m0.04534  \u001b[39m |\n| \u001b[39m29       \u001b[39m | \u001b[39m0.735    \u001b[39m | \u001b[39m15.78    \u001b[39m | \u001b[39m0.002309 \u001b[39m |\n| \u001b[35m30       \u001b[39m | \u001b[35m0.775    \u001b[39m | \u001b[35m15.47    \u001b[39m | \u001b[35m0.01345  \u001b[39m |\n| \u001b[39m31       \u001b[39m | \u001b[39m0.73     \u001b[39m | \u001b[39m46.57    \u001b[39m | \u001b[39m0.0776   \u001b[39m |\n| \u001b[39m32       \u001b[39m | \u001b[39m0.76     \u001b[39m | \u001b[39m11.6     \u001b[39m | \u001b[39m0.009568 \u001b[39m |\n| \u001b[39m33       \u001b[39m | \u001b[39m0.775    \u001b[39m | \u001b[39m15.49    \u001b[39m | \u001b[39m0.01225  \u001b[39m |\n| \u001b[39m34       \u001b[39m | \u001b[39m0.73     \u001b[39m | \u001b[39m92.01    \u001b[39m | \u001b[39m0.07994  \u001b[39m |\n| \u001b[39m35       \u001b[39m | \u001b[39m0.765    \u001b[39m | \u001b[39m79.02    \u001b[39m | \u001b[39m0.007546 \u001b[39m |\n| \u001b[39m36       \u001b[39m | \u001b[39m0.715    \u001b[39m | \u001b[39m21.6     \u001b[39m | \u001b[39m0.08416  \u001b[39m |\n| \u001b[39m37       \u001b[39m | \u001b[39m0.745    \u001b[39m | \u001b[39m79.01    \u001b[39m | \u001b[39m0.02592  \u001b[39m |\n| \u001b[39m38       \u001b[39m | \u001b[39m0.725    \u001b[39m | \u001b[39m15.48    \u001b[39m | \u001b[39m0.001637 \u001b[39m |\n| \u001b[35m39       \u001b[39m | \u001b[35m0.78     \u001b[39m | \u001b[35m15.46    \u001b[39m | \u001b[35m0.01195  \u001b[39m |\n| \u001b[39m40       \u001b[39m | \u001b[39m0.745    \u001b[39m | \u001b[39m15.05    \u001b[39m | \u001b[39m0.04515  \u001b[39m |\n| \u001b[39m41       \u001b[39m | \u001b[39m0.725    \u001b[39m | \u001b[39m79.04    \u001b[39m | \u001b[39m0.004336 \u001b[39m |\n| \u001b[39m42       \u001b[39m | \u001b[39m0.76     \u001b[39m | \u001b[39m88.55    \u001b[39m | \u001b[39m0.01509  \u001b[39m |\n| \u001b[39m43       \u001b[39m | \u001b[39m0.745    \u001b[39m | \u001b[39m15.75    \u001b[39m | \u001b[39m0.004753 \u001b[39m |\n| \u001b[39m44       \u001b[39m | \u001b[39m0.725    \u001b[39m | \u001b[39m99.91    \u001b[39m | \u001b[39m0.04861  \u001b[39m |\n| \u001b[39m45       \u001b[39m | \u001b[39m0.745    \u001b[39m | \u001b[39m85.98    \u001b[39m | \u001b[39m0.0243   \u001b[39m |\n| \u001b[39m46       \u001b[39m | \u001b[39m0.745    \u001b[39m | \u001b[39m15.51    \u001b[39m | \u001b[39m0.008581 \u001b[39m |\n| \u001b[39m47       \u001b[39m | \u001b[39m0.77     \u001b[39m | \u001b[39m15.49    \u001b[39m | \u001b[39m0.0183   \u001b[39m |\n| \u001b[39m48       \u001b[39m | \u001b[39m0.765    \u001b[39m | \u001b[39m15.7     \u001b[39m | \u001b[39m0.01511  \u001b[39m |\n| \u001b[39m49       \u001b[39m | \u001b[39m0.715    \u001b[39m | \u001b[39m65.7     \u001b[39m | \u001b[39m0.08686  \u001b[39m |\n| \u001b[39m50       \u001b[39m | \u001b[39m0.75     \u001b[39m | \u001b[39m15.47    \u001b[39m | \u001b[39m0.02208  \u001b[39m |\n| \u001b[39m51       \u001b[39m | \u001b[39m0.71     \u001b[39m | \u001b[39m11.86    \u001b[39m | \u001b[39m0.08962  \u001b[39m |\n| \u001b[39m52       \u001b[39m | \u001b[39m0.765    \u001b[39m | \u001b[39m11.62    \u001b[39m | \u001b[39m0.01427  \u001b[39m |\n| \u001b[39m53       \u001b[39m | \u001b[39m0.71     \u001b[39m | \u001b[39m13.65    \u001b[39m | \u001b[39m0.08892  \u001b[39m |\n| \u001b[39m54       \u001b[39m | \u001b[39m0.76     \u001b[39m | \u001b[39m88.55    \u001b[39m | \u001b[39m0.02942  \u001b[39m |\n| \u001b[39m55       \u001b[39m | \u001b[39m0.765    \u001b[39m | \u001b[39m11.58    \u001b[39m | \u001b[39m0.01003  \u001b[39m |\n| \u001b[39m56       \u001b[39m | \u001b[39m0.675    \u001b[39m | \u001b[39m38.58    \u001b[39m | \u001b[39m0.09954  \u001b[39m |\n| \u001b[39m57       \u001b[39m | \u001b[39m0.725    \u001b[39m | \u001b[39m62.62    \u001b[39m | \u001b[39m0.05031  \u001b[39m |\n| \u001b[39m58       \u001b[39m | \u001b[39m0.765    \u001b[39m | \u001b[39m78.99    \u001b[39m | \u001b[39m0.007432 \u001b[39m |\n| \u001b[39m59       \u001b[39m | \u001b[39m0.755    \u001b[39m | \u001b[39m88.63    \u001b[39m | \u001b[39m0.00795  \u001b[39m |\n| \u001b[39m60       \u001b[39m | \u001b[39m0.755    \u001b[39m | \u001b[39m15.69    \u001b[39m | \u001b[39m0.02963  \u001b[39m |\n| \u001b[39m61       \u001b[39m | \u001b[39m0.75     \u001b[39m | \u001b[39m88.54    \u001b[39m | \u001b[39m0.04345  \u001b[39m |\n| \u001b[39m62       \u001b[39m | \u001b[39m0.76     \u001b[39m | \u001b[39m88.56    \u001b[39m | \u001b[39m0.01489  \u001b[39m |\n| \u001b[39m63       \u001b[39m | \u001b[39m0.695    \u001b[39m | \u001b[39m11.63    \u001b[39m | \u001b[39m0.00139  \u001b[39m |\n| \u001b[39m64       \u001b[39m | \u001b[39m0.75     \u001b[39m | \u001b[39m15.7     \u001b[39m | \u001b[39m0.02812  \u001b[39m |\n| \u001b[39m65       \u001b[39m | \u001b[39m0.74     \u001b[39m | \u001b[39m15.3     \u001b[39m | \u001b[39m0.05494  \u001b[39m |\n| \u001b[39m66       \u001b[39m | \u001b[39m0.745    \u001b[39m | \u001b[39m15.65    \u001b[39m | \u001b[39m0.005202 \u001b[39m |\n| \u001b[39m67       \u001b[39m | \u001b[39m0.77     \u001b[39m | \u001b[39m78.98    \u001b[39m | \u001b[39m0.006914 \u001b[39m |\n| \u001b[39m68       \u001b[39m | \u001b[39m0.76     \u001b[39m | \u001b[39m78.98    \u001b[39m | \u001b[39m0.01281  \u001b[39m |\n| \u001b[39m69       \u001b[39m | \u001b[39m0.765    \u001b[39m | \u001b[39m79.01    \u001b[39m | \u001b[39m0.006144 \u001b[39m |\n| \u001b[39m70       \u001b[39m | \u001b[39m0.765    \u001b[39m | \u001b[39m78.97    \u001b[39m | \u001b[39m0.01871  \u001b[39m |\n| \u001b[39m71       \u001b[39m | \u001b[39m0.76     \u001b[39m | \u001b[39m78.95    \u001b[39m | \u001b[39m0.01142  \u001b[39m |\n| \u001b[39m72       \u001b[39m | \u001b[39m0.755    \u001b[39m | \u001b[39m79.02    \u001b[39m | \u001b[39m0.008349 \u001b[39m |\n| \u001b[39m73       \u001b[39m | \u001b[39m0.75     \u001b[39m | \u001b[39m78.96    \u001b[39m | \u001b[39m0.02762  \u001b[39m |\n| \u001b[39m74       \u001b[39m | \u001b[39m0.76     \u001b[39m | \u001b[39m15.44    \u001b[39m | \u001b[39m0.02099  \u001b[39m |\n| \u001b[39m75       \u001b[39m | \u001b[39m0.735    \u001b[39m | \u001b[39m40.35    \u001b[39m | \u001b[39m0.0528   \u001b[39m |\n| \u001b[39m76       \u001b[39m | \u001b[39m0.73     \u001b[39m | \u001b[39m78.97    \u001b[39m | \u001b[39m0.002254 \u001b[39m |\n| \u001b[39m77       \u001b[39m | \u001b[39m0.75     \u001b[39m | \u001b[39m15.46    \u001b[39m | \u001b[39m0.02158  \u001b[39m |\n| \u001b[39m78       \u001b[39m | \u001b[39m0.745    \u001b[39m | \u001b[39m93.68    \u001b[39m | \u001b[39m0.04612  \u001b[39m |\n| \u001b[39m79       \u001b[39m | \u001b[39m0.69     \u001b[39m | \u001b[39m53.92    \u001b[39m | \u001b[39m0.09491  \u001b[39m |\n| \u001b[39m80       \u001b[39m | \u001b[39m0.76     \u001b[39m | \u001b[39m15.77    \u001b[39m | \u001b[39m0.03266  \u001b[39m |\n| \u001b[39m81       \u001b[39m | \u001b[39m0.755    \u001b[39m | \u001b[39m15.77    \u001b[39m | \u001b[39m0.03379  \u001b[39m |\n| \u001b[39m82       \u001b[39m | \u001b[39m0.745    \u001b[39m | \u001b[39m88.53    \u001b[39m | \u001b[39m0.00522  \u001b[39m |\n| \u001b[39m83       \u001b[39m | \u001b[39m0.76     \u001b[39m | \u001b[39m41.29    \u001b[39m | \u001b[39m0.01576  \u001b[39m |\n| \u001b[39m84       \u001b[39m | \u001b[39m0.73     \u001b[39m | \u001b[39m32.29    \u001b[39m | \u001b[39m0.06467  \u001b[39m |\n| \u001b[39m85       \u001b[39m | \u001b[39m0.73     \u001b[39m | \u001b[39m79.02    \u001b[39m | \u001b[39m0.002733 \u001b[39m |\n| \u001b[39m86       \u001b[39m | \u001b[39m0.765    \u001b[39m | \u001b[39m11.61    \u001b[39m | \u001b[39m0.01021  \u001b[39m |\n| \u001b[39m87       \u001b[39m | \u001b[39m0.725    \u001b[39m | \u001b[39m78.99    \u001b[39m | \u001b[39m0.001985 \u001b[39m |\n| \u001b[39m88       \u001b[39m | \u001b[39m0.76     \u001b[39m | \u001b[39m79.01    \u001b[39m | \u001b[39m0.01416  \u001b[39m |\n| \u001b[39m89       \u001b[39m | \u001b[39m0.75     \u001b[39m | \u001b[39m96.4     \u001b[39m | \u001b[39m0.03846  \u001b[39m |\n| \u001b[39m90       \u001b[39m | \u001b[39m0.735    \u001b[39m | \u001b[39m15.46    \u001b[39m | \u001b[39m0.002052 \u001b[39m |\n| \u001b[39m91       \u001b[39m | \u001b[39m0.745    \u001b[39m | \u001b[39m11.58    \u001b[39m | \u001b[39m0.003444 \u001b[39m |\n| \u001b[39m92       \u001b[39m | \u001b[39m0.735    \u001b[39m | \u001b[39m63.2     \u001b[39m | \u001b[39m0.05247  \u001b[39m |\n| \u001b[39m93       \u001b[39m | \u001b[39m0.77     \u001b[39m | \u001b[39m15.49    \u001b[39m | \u001b[39m0.01637  \u001b[39m |\n| \u001b[39m94       \u001b[39m | \u001b[39m0.77     \u001b[39m | \u001b[39m15.76    \u001b[39m | \u001b[39m0.01699  \u001b[39m |\n| \u001b[39m95       \u001b[39m | \u001b[39m0.755    \u001b[39m | \u001b[39m11.58    \u001b[39m | \u001b[39m0.03158  \u001b[39m |\n| \u001b[39m96       \u001b[39m | \u001b[39m0.75     \u001b[39m | \u001b[39m15.49    \u001b[39m | \u001b[39m0.02695  \u001b[39m |\n| \u001b[39m97       \u001b[39m | \u001b[39m0.765    \u001b[39m | \u001b[39m78.94    \u001b[39m | \u001b[39m0.006358 \u001b[39m |\n| \u001b[39m98       \u001b[39m | \u001b[39m0.695    \u001b[39m | \u001b[39m84.75    \u001b[39m | \u001b[39m0.0002544\u001b[39m |\n| \u001b[39m99       \u001b[39m | \u001b[39m0.76     \u001b[39m | \u001b[39m11.6     \u001b[39m | \u001b[39m0.02079  \u001b[39m |\n| \u001b[39m100      \u001b[39m | \u001b[39m0.745    \u001b[39m | \u001b[39m15.69    \u001b[39m | \u001b[39m0.02316  \u001b[39m |\n| \u001b[39m101      \u001b[39m | \u001b[39m0.755    \u001b[39m | \u001b[39m15.67    \u001b[39m | \u001b[39m0.03075  \u001b[39m |\n| \u001b[39m102      \u001b[39m | \u001b[39m0.77     \u001b[39m | \u001b[39m15.76    \u001b[39m | \u001b[39m0.01855  \u001b[39m |\n| \u001b[39m103      \u001b[39m | \u001b[39m0.715    \u001b[39m | \u001b[39m88.55    \u001b[39m | \u001b[39m0.003379 \u001b[39m |\n| \u001b[39m104      \u001b[39m | \u001b[39m0.76     \u001b[39m | \u001b[39m79.0     \u001b[39m | \u001b[39m0.01932  \u001b[39m |\n| \u001b[39m105      \u001b[39m | \u001b[39m0.76     \u001b[39m | \u001b[39m84.39    \u001b[39m | \u001b[39m0.01719  \u001b[39m |\n=================================================\nHyperparameters tuning time: 42.028 seconds\nMeilleurs hyperparamètres : {'target': 0.78, 'params': {'C': 15.463135044351636, 'gamma': 0.011949351027526894}}\nTraining time: 0.224 seconds\nTest (prediction) time: 0.013 seconds\nRapport de classification :\n               precision    recall  f1-score   support\n\n       blues       0.81      0.85      0.83        20\n   classical       0.85      0.85      0.85        20\n     country       0.85      0.85      0.85        20\n       disco       0.75      0.60      0.67        20\n      hiphop       0.77      0.85      0.81        20\n        jazz       0.71      0.85      0.77        20\n       metal       0.94      0.85      0.89        20\n         pop       0.70      0.70      0.70        20\n      reggae       0.71      0.75      0.73        20\n        rock       0.72      0.65      0.68        20\n\n    accuracy                           0.78       200\n   macro avg       0.78      0.78      0.78       200\nweighted avg       0.78      0.78      0.78       200\n\nMatrice de confusion :\n [[17  0  1  0  0  1  0  0  1  0]\n [ 0 17  0  0  0  3  0  0  0  0]\n [ 1  0 17  0  0  0  0  0  1  1]\n [ 0  1  0 12  2  0  1  3  0  1]\n [ 0  0  0  1 17  0  0  1  1  0]\n [ 1  1  0  0  0 17  0  0  0  1]\n [ 2  0  0  1  0  0 17  0  0  0]\n [ 0  0  0  1  0  2  0 14  3  0]\n [ 0  1  0  1  1  0  0  0 15  2]\n [ 0  0  2  0  2  1  0  2  0 13]]\n","output_type":"stream"}],"execution_count":18},{"cell_type":"code","source":"from sklearn.linear_model import LogisticRegression\nfrom sklearn.metrics import classification_report, confusion_matrix, roc_auc_score, RocCurveDisplay\nfrom bayes_opt import BayesianOptimization\nimport numpy as np\nimport matplotlib.pyplot as plt\n\n# Prétraitement des données\nX = df.drop(columns=['label'])  # Supprimez les colonnes non pertinentes\ny = df['label']\n\n# Encoder la variable cible\nencoder = LabelEncoder()\ny = encoder.fit_transform(y)\n\n# Normaliser les données\nscaler = StandardScaler()\nX_scaled = scaler.fit_transform(X)\n\n# Diviser les données en ensembles d'entraînement et de test\nX_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.2, random_state=42, stratify=y)\n\n# Fonction d'évaluation pour BayesianOptimization\ndef optimize_logistic_regression(C, tol):\n    model = LogisticRegression(C=C, tol=tol, max_iter=500, random_state=42)\n    model.fit(X_train, y_train)\n    return model.score(X_test, y_test)\n\n# Définir les limites des hyperparamètres\nparam_bounds = {\n    'C': (0.001, 10),\n    'tol': (1e-6, 1e-2)\n}\n\n# Lancer l'optimisation\noptimizer = BayesianOptimization(f=optimize_logistic_regression, pbounds=param_bounds, random_state=42)\nstart_opt = time.time_ns()\noptimizer.maximize(init_points=5, n_iter=20)\nend_opt = time.time_ns()\nopt_time = (end_opt - start_opt) / 1e9  # Convert nanoseconds to seconds\n\nprint(f\"Hyperparameters tuning time: {opt_time:.3f} seconds\")\n\n# Extraire les meilleurs hyperparamètres\nbest_params = optimizer.max\nprint(\"Meilleurs hyperparamètres :\", best_params)\n\n# Entraîner le modèle avec les meilleurs hyperparamètres\nbest_model = LogisticRegression(C=best_params['params']['C'], tol=best_params['params']['tol'], max_iter=500, random_state=42)\nstart_train = time.time_ns()\nbest_model.fit(X_train, y_train)\nend_train = time.time_ns()\ntrain_time = (end_train - start_train) / 1e9  # Convert nanoseconds to seconds\nprint(f\"Training time: {train_time:.3f} seconds\")\n\n# Évaluation du modèle\n# Test (prediction) time\nstart_test = time.time_ns()\ny_pred = best_model.predict(X_test)\nend_test = time.time_ns()\ntest_time = (end_test - start_test) / 1e9  # Convert nanoseconds to seconds\nprint(f\"Test (prediction) time: {test_time:.3f} seconds\")\nprint(\"Rapport de classification :\\n\", classification_report(y_test, y_pred, target_names=encoder.classes_))\n\n# Matrice de confusion\nconf_matrix = confusion_matrix(y_test, y_pred)\nprint(\"Matrice de confusion :\\n\", conf_matrix)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-16T02:50:12.493557Z","iopub.execute_input":"2025-02-16T02:50:12.493903Z","iopub.status.idle":"2025-02-16T02:50:15.915563Z","shell.execute_reply.started":"2025-02-16T02:50:12.493868Z","shell.execute_reply":"2025-02-16T02:50:15.914427Z"}},"outputs":[{"name":"stdout","text":"|   iter    |  target   |     C     |    tol    |\n-------------------------------------------------\n| \u001b[39m1        \u001b[39m | \u001b[39m0.695    \u001b[39m | \u001b[39m3.746    \u001b[39m | \u001b[39m0.009507 \u001b[39m |\n| \u001b[35m2        \u001b[39m | \u001b[35m0.71     \u001b[39m | \u001b[35m7.32     \u001b[39m | \u001b[35m0.005987 \u001b[39m |\n| \u001b[39m3        \u001b[39m | \u001b[39m0.71     \u001b[39m | \u001b[39m1.561    \u001b[39m | \u001b[39m0.001561 \u001b[39m |\n| \u001b[35m4        \u001b[39m | \u001b[35m0.72     \u001b[39m | \u001b[35m0.5818   \u001b[39m | \u001b[35m0.008662 \u001b[39m |\n| \u001b[39m5        \u001b[39m | \u001b[39m0.705    \u001b[39m | \u001b[39m6.012    \u001b[39m | \u001b[39m0.007081 \u001b[39m |\n| \u001b[39m6        \u001b[39m | \u001b[39m0.69     \u001b[39m | \u001b[39m9.997    \u001b[39m | \u001b[39m0.009966 \u001b[39m |\n| \u001b[39m7        \u001b[39m | \u001b[39m0.515    \u001b[39m | \u001b[39m0.001055 \u001b[39m | \u001b[39m0.003255 \u001b[39m |\n| \u001b[39m8        \u001b[39m | \u001b[39m0.71     \u001b[39m | \u001b[39m1.014    \u001b[39m | \u001b[39m0.005217 \u001b[39m |\n| \u001b[39m9        \u001b[39m | \u001b[39m0.675    \u001b[39m | \u001b[39m0.05743  \u001b[39m | \u001b[39m0.004638 \u001b[39m |\n| \u001b[39m10       \u001b[39m | \u001b[39m0.705    \u001b[39m | \u001b[39m6.676    \u001b[39m | \u001b[39m0.006422 \u001b[39m |\n| \u001b[39m11       \u001b[39m | \u001b[39m0.72     \u001b[39m | \u001b[39m0.3257   \u001b[39m | \u001b[39m0.002153 \u001b[39m |\n| \u001b[39m12       \u001b[39m | \u001b[39m0.7      \u001b[39m | \u001b[39m4.419    \u001b[39m | \u001b[39m0.008244 \u001b[39m |\n| \u001b[39m13       \u001b[39m | \u001b[39m0.72     \u001b[39m | \u001b[39m0.5416   \u001b[39m | \u001b[39m0.008395 \u001b[39m |\n| \u001b[35m14       \u001b[39m | \u001b[35m0.725    \u001b[39m | \u001b[35m0.2745   \u001b[39m | \u001b[35m0.0082   \u001b[39m |\n| \u001b[39m15       \u001b[39m | \u001b[39m0.705    \u001b[39m | \u001b[39m6.902    \u001b[39m | \u001b[39m0.001225 \u001b[39m |\n| \u001b[39m16       \u001b[39m | \u001b[39m0.705    \u001b[39m | \u001b[39m6.041    \u001b[39m | \u001b[39m0.001518 \u001b[39m |\n| \u001b[39m17       \u001b[39m | \u001b[39m0.71     \u001b[39m | \u001b[39m0.2093   \u001b[39m | \u001b[39m0.003092 \u001b[39m |\n| \u001b[39m18       \u001b[39m | \u001b[39m0.685    \u001b[39m | \u001b[39m0.1324   \u001b[39m | \u001b[39m0.006605 \u001b[39m |\n| \u001b[39m19       \u001b[39m | \u001b[39m0.72     \u001b[39m | \u001b[39m0.3955   \u001b[39m | \u001b[39m0.009175 \u001b[39m |\n| \u001b[39m20       \u001b[39m | \u001b[39m0.725    \u001b[39m | \u001b[39m0.2684   \u001b[39m | \u001b[39m0.008652 \u001b[39m |\n| \u001b[39m21       \u001b[39m | \u001b[39m0.72     \u001b[39m | \u001b[39m0.4648   \u001b[39m | \u001b[39m0.00193  \u001b[39m |\n| \u001b[39m22       \u001b[39m | \u001b[39m0.72     \u001b[39m | \u001b[39m0.6755   \u001b[39m | \u001b[39m0.003975 \u001b[39m |\n| \u001b[39m23       \u001b[39m | \u001b[39m0.705    \u001b[39m | \u001b[39m6.011    \u001b[39m | \u001b[39m0.006954 \u001b[39m |\n| \u001b[39m24       \u001b[39m | \u001b[39m0.72     \u001b[39m | \u001b[39m0.7682   \u001b[39m | \u001b[39m0.007971 \u001b[39m |\n| \u001b[39m25       \u001b[39m | \u001b[39m0.715    \u001b[39m | \u001b[39m0.8635   \u001b[39m | \u001b[39m0.004008 \u001b[39m |\n=================================================\nHyperparameters tuning time: 3.322 seconds\nMeilleurs hyperparamètres : {'target': 0.725, 'params': {'C': 0.27446446909335803, 'tol': 0.008199652955909064}}\nTraining time: 0.067 seconds\nTest (prediction) time: 0.001 seconds\nRapport de classification :\n               precision    recall  f1-score   support\n\n       blues       0.72      0.65      0.68        20\n   classical       0.95      0.95      0.95        20\n     country       0.67      0.70      0.68        20\n       disco       0.77      0.50      0.61        20\n      hiphop       0.62      0.65      0.63        20\n        jazz       0.77      0.85      0.81        20\n       metal       0.94      0.75      0.83        20\n         pop       0.82      0.90      0.86        20\n      reggae       0.60      0.75      0.67        20\n        rock       0.50      0.55      0.52        20\n\n    accuracy                           0.73       200\n   macro avg       0.74      0.72      0.72       200\nweighted avg       0.74      0.72      0.72       200\n\nMatrice de confusion :\n [[13  0  2  0  0  2  0  0  2  1]\n [ 0 19  0  0  0  1  0  0  0  0]\n [ 2  0 14  0  0  1  0  0  1  2]\n [ 0  0  1 10  5  0  0  2  0  2]\n [ 1  0  0  1 13  0  0  0  5  0]\n [ 1  1  0  0  0 17  0  0  0  1]\n [ 1  0  0  0  2  0 15  0  0  2]\n [ 0  0  0  1  0  0  0 18  1  0]\n [ 0  0  0  1  1  0  0  0 15  3]\n [ 0  0  4  0  0  1  1  2  1 11]]\n","output_type":"stream"}],"execution_count":19},{"cell_type":"code","source":"import pandas as pd\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import LabelEncoder, StandardScaler\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.metrics import classification_report, confusion_matrix, roc_auc_score, RocCurveDisplay\nfrom bayes_opt import BayesianOptimization\nimport numpy as np\nimport matplotlib.pyplot as plt\n\n# Prétraitement des données\nX = df.drop(columns=['label'])  # Supprimez les colonnes non pertinentes\ny = df['label']\n\n# Encoder la variable cible\nencoder = LabelEncoder()\ny = encoder.fit_transform(y)\n\n# Normaliser les données\nscaler = StandardScaler()\nX_scaled = scaler.fit_transform(X)\n\n# Diviser les données en ensembles d'entraînement et de test\nX_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.2, random_state=42, stratify=y)\n\n# Fonction d'évaluation pour BayesianOptimization\ndef optimize_knn(n_neighbors, p):\n    model = KNeighborsClassifier(\n        n_neighbors=int(n_neighbors),  # Convertir en entier\n        p=int(p),                      # Distance : 1 pour Manhattan, 2 pour Euclidean\n        metric='minkowski'\n    )\n    model.fit(X_train, y_train)\n    return model.score(X_test, y_test)\n\n# Définir les limites des hyperparamètres\nparam_bounds = {\n    'n_neighbors': (1, 50),  # Nombre de voisins\n    'p': (1, 2)             # Distance : 1 (Manhattan) ou 2 (Euclidean)\n}\n\n# Lancer l'optimisation\noptimizer = BayesianOptimization(f=optimize_knn, pbounds=param_bounds, random_state=42)\nstart_opt = time.time_ns()\noptimizer.maximize(init_points=5, n_iter=20)\nend_opt = time.time_ns()\nopt_time = (end_opt - start_opt) / 1e9  # Convert nanoseconds to seconds\n\nprint(f\"Hyperparameters tuning time: {opt_time:.3f} seconds\")\n\n# Extraire les meilleurs hyperparamètres\nbest_params = optimizer.max\nprint(\"Meilleurs hyperparamètres :\", best_params)\n\n# Entraîner le modèle avec les meilleurs hyperparamètres\nbest_model = KNeighborsClassifier(\n    n_neighbors=int(best_params['params']['n_neighbors']),\n    p=int(best_params['params']['p']),\n    metric='minkowski'\n)\nstart_train = time.time_ns()\nbest_model.fit(X_train, y_train)\nend_train = time.time_ns()\ntrain_time = (end_train - start_train) / 1e9  # Convert nanoseconds to seconds\nprint(f\"Training time: {train_time:.3f} seconds\")\n\n# Évaluation du modèle\nstart_test = time.time_ns()\ny_pred = best_model.predict(X_test)\nend_test = time.time_ns()\ntest_time = (end_test - start_test) / 1e9  # Convert nanoseconds to seconds\nprint(f\"Test (prediction) time: {test_time:.3f} seconds\")\nprint(\"Rapport de classification :\\n\", classification_report(y_test, y_pred, target_names=encoder.classes_))\n\n# Matrice de confusion\nconf_matrix = confusion_matrix(y_test, y_pred)\nprint(\"Matrice de confusion :\\n\", conf_matrix)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-16T02:50:15.917053Z","iopub.execute_input":"2025-02-16T02:50:15.917362Z","iopub.status.idle":"2025-02-16T02:50:19.311462Z","shell.execute_reply.started":"2025-02-16T02:50:15.917333Z","shell.execute_reply":"2025-02-16T02:50:19.310325Z"}},"outputs":[{"name":"stdout","text":"|   iter    |  target   | n_neig... |     p     |\n-------------------------------------------------\n| \u001b[39m1        \u001b[39m | \u001b[39m0.68     \u001b[39m | \u001b[39m19.35    \u001b[39m | \u001b[39m1.951    \u001b[39m |\n| \u001b[39m2        \u001b[39m | \u001b[39m0.63     \u001b[39m | \u001b[39m36.87    \u001b[39m | \u001b[39m1.599    \u001b[39m |\n| \u001b[35m3        \u001b[39m | \u001b[35m0.695    \u001b[39m | \u001b[35m8.645    \u001b[39m | \u001b[35m1.156    \u001b[39m |\n| \u001b[39m4        \u001b[39m | \u001b[39m0.655    \u001b[39m | \u001b[39m3.846    \u001b[39m | \u001b[39m1.866    \u001b[39m |\n| \u001b[39m5        \u001b[39m | \u001b[39m0.645    \u001b[39m | \u001b[39m30.45    \u001b[39m | \u001b[39m1.708    \u001b[39m |\n| \u001b[39m6        \u001b[39m | \u001b[39m0.695    \u001b[39m | \u001b[39m8.629    \u001b[39m | \u001b[39m1.226    \u001b[39m |\n| \u001b[35m7        \u001b[39m | \u001b[35m0.71     \u001b[39m | \u001b[35m13.11    \u001b[39m | \u001b[35m1.984    \u001b[39m |\n| \u001b[39m8        \u001b[39m | \u001b[39m0.59     \u001b[39m | \u001b[39m49.98    \u001b[39m | \u001b[39m1.076    \u001b[39m |\n| \u001b[39m9        \u001b[39m | \u001b[39m0.71     \u001b[39m | \u001b[39m13.59    \u001b[39m | \u001b[39m1.014    \u001b[39m |\n| \u001b[39m10       \u001b[39m | \u001b[39m0.705    \u001b[39m | \u001b[39m12.04    \u001b[39m | \u001b[39m1.015    \u001b[39m |\n| \u001b[39m11       \u001b[39m | \u001b[39m0.68     \u001b[39m | \u001b[39m15.34    \u001b[39m | \u001b[39m1.994    \u001b[39m |\n| \u001b[39m12       \u001b[39m | \u001b[39m0.675    \u001b[39m | \u001b[39m23.98    \u001b[39m | \u001b[39m1.01     \u001b[39m |\n| \u001b[39m13       \u001b[39m | \u001b[39m0.585    \u001b[39m | \u001b[39m42.79    \u001b[39m | \u001b[39m1.996    \u001b[39m |\n| \u001b[39m14       \u001b[39m | \u001b[39m0.69     \u001b[39m | \u001b[39m10.64    \u001b[39m | \u001b[39m1.993    \u001b[39m |\n| \u001b[39m15       \u001b[39m | \u001b[39m0.675    \u001b[39m | \u001b[39m21.16    \u001b[39m | \u001b[39m1.002    \u001b[39m |\n| \u001b[39m16       \u001b[39m | \u001b[39m0.69     \u001b[39m | \u001b[39m6.753    \u001b[39m | \u001b[39m1.043    \u001b[39m |\n| \u001b[39m17       \u001b[39m | \u001b[39m0.71     \u001b[39m | \u001b[39m13.01    \u001b[39m | \u001b[39m1.003    \u001b[39m |\n| \u001b[39m18       \u001b[39m | \u001b[39m0.655    \u001b[39m | \u001b[39m26.7     \u001b[39m | \u001b[39m1.977    \u001b[39m |\n| \u001b[39m19       \u001b[39m | \u001b[39m0.71     \u001b[39m | \u001b[39m13.32    \u001b[39m | \u001b[39m1.5      \u001b[39m |\n| \u001b[39m20       \u001b[39m | \u001b[39m0.705    \u001b[39m | \u001b[39m12.5     \u001b[39m | \u001b[39m1.993    \u001b[39m |\n| \u001b[39m21       \u001b[39m | \u001b[39m0.67     \u001b[39m | \u001b[39m1.0      \u001b[39m | \u001b[39m1.2      \u001b[39m |\n| \u001b[39m22       \u001b[39m | \u001b[39m0.71     \u001b[39m | \u001b[39m13.65    \u001b[39m | \u001b[39m1.997    \u001b[39m |\n| \u001b[39m23       \u001b[39m | \u001b[39m0.71     \u001b[39m | \u001b[39m13.31    \u001b[39m | \u001b[39m1.002    \u001b[39m |\n| \u001b[39m24       \u001b[39m | \u001b[39m0.71     \u001b[39m | \u001b[39m13.38    \u001b[39m | \u001b[39m1.993    \u001b[39m |\n| \u001b[39m25       \u001b[39m | \u001b[39m0.67     \u001b[39m | \u001b[39m22.09    \u001b[39m | \u001b[39m1.995    \u001b[39m |\n=================================================\nHyperparameters tuning time: 3.205 seconds\nMeilleurs hyperparamètres : {'target': 0.71, 'params': {'n_neighbors': 13.112088322552237, 'p': 1.9835720017720195}}\nTraining time: 0.002 seconds\nTest (prediction) time: 0.021 seconds\nRapport de classification :\n               precision    recall  f1-score   support\n\n       blues       0.85      0.55      0.67        20\n   classical       0.83      1.00      0.91        20\n     country       0.64      0.90      0.75        20\n       disco       0.46      0.55      0.50        20\n      hiphop       0.72      0.65      0.68        20\n        jazz       0.93      0.65      0.76        20\n       metal       0.78      0.70      0.74        20\n         pop       0.83      0.95      0.88        20\n      reggae       0.67      0.50      0.57        20\n        rock       0.57      0.65      0.60        20\n\n    accuracy                           0.71       200\n   macro avg       0.73      0.71      0.71       200\nweighted avg       0.73      0.71      0.71       200\n\nMatrice de confusion :\n [[11  0  3  0  0  1  0  0  3  2]\n [ 0 20  0  0  0  0  0  0  0  0]\n [ 0  0 18  0  0  0  0  0  0  2]\n [ 0  1  1 11  1  0  3  2  0  1]\n [ 0  0  0  4 13  0  1  1  1  0]\n [ 1  3  1  2  0 13  0  0  0  0]\n [ 1  0  1  1  0  0 14  0  0  3]\n [ 0  0  0  1  0  0  0 19  0  0]\n [ 0  0  2  2  4  0  0  0 10  2]\n [ 0  0  2  3  0  0  0  1  1 13]]\n","output_type":"stream"}],"execution_count":20},{"cell_type":"code","source":"# Import necessary libraries\nimport pandas as pd\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import LabelEncoder, StandardScaler\nfrom sklearn.metrics import classification_report, confusion_matrix, roc_auc_score, RocCurveDisplay\nfrom bayes_opt import BayesianOptimization\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom sklearn.ensemble import RandomForestClassifier\n\n\n# Prétraitement des données\nX = df.drop(columns=['label'])  # Supprimez les colonnes non pertinentes\ny = df['label']\n\n# Encoder la variable cible\nencoder = LabelEncoder()\ny = encoder.fit_transform(y)\n\n# No need to Normaliser les données\n# scaler = StandardScaler()\n# X_scaled = scaler.fit_transform(X)\n\n# Diviser les données en ensembles d'entraînement et de test\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42, stratify=y)\n# Function for Bayesian Optimization with Random Forest\ndef optimize_rf(n_estimators, max_depth):\n    # Convert float parameters to integers as RandomForest expects integers\n    n_estimators = int(n_estimators)\n    max_depth = int(max_depth)\n    \n    model = RandomForestClassifier(\n        n_estimators=n_estimators, \n        max_depth=max_depth, \n        random_state=42,\n        n_jobs=-1\n    )\n    model.fit(X_train, y_train)\n    return model.score(X_test, y_test)\n\n# Define parameter bounds for Random Forest\nparam_bounds_rf = {\n    'n_estimators': (10, 200),  # Number of trees\n    'max_depth': (5, 50)       # Maximum depth of the trees\n}\n\n# Run Bayesian Optimization\noptimizer_rf = BayesianOptimization(f=optimize_rf, pbounds=param_bounds_rf, random_state=42)\nstart_opt = time.time_ns()\noptimizer_rf.maximize(init_points=5, n_iter=50)\nend_opt = time.time_ns()\nopt_time = (end_opt - start_opt) / 1e9  # Convert nanoseconds to seconds\n\nprint(f\"Hyperparameters tuning time: {opt_time:.3f} seconds\")\n\n# Extract the best parameters\nbest_params_rf = optimizer_rf.max\nprint(\"Meilleurs hyperparamètres :\", best_params_rf)\n\n# Train the model with the best hyperparameters\nbest_model_rf = RandomForestClassifier(\n    n_estimators=50,\n    max_depth=25,\n    random_state=42,\n    n_jobs=-1\n)\nstart_train = time.time_ns()\nbest_model_rf.fit(X_train, y_train) \nend_train = time.time_ns()\ntrain_time = (end_train - start_train) / 1e9  # Convert nanoseconds to seconds\nprint(f\"Training time: {train_time:.3f} seconds\")\n\n# Model evaluation\nstart_test = time.time_ns()\ny_pred_rf = best_model_rf.predict(X_test)\nend_test = time.time_ns()\ntest_time = (end_test - start_test) / 1e9  # Convert nanoseconds to seconds\nprint(f\"Test (prediction) time: {test_time:.3f} seconds\")\nprint(\"Rapport de classification :\\n\", classification_report(y_test, y_pred_rf, target_names=encoder.classes_))\n\n# Confusion matrix\nconf_matrix_rf = confusion_matrix(y_test, y_pred_rf)\nprint(\"Matrice de confusion :\\n\", conf_matrix_rf)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-16T02:50:19.312440Z","iopub.execute_input":"2025-02-16T02:50:19.312746Z","iopub.status.idle":"2025-02-16T02:50:57.414845Z","shell.execute_reply.started":"2025-02-16T02:50:19.312719Z","shell.execute_reply":"2025-02-16T02:50:57.413800Z"}},"outputs":[{"name":"stdout","text":"|   iter    |  target   | max_depth | n_esti... |\n-------------------------------------------------\n| \u001b[39m1        \u001b[39m | \u001b[39m0.7133   \u001b[39m | \u001b[39m21.85    \u001b[39m | \u001b[39m190.6    \u001b[39m |\n| \u001b[39m2        \u001b[39m | \u001b[39m0.7033   \u001b[39m | \u001b[39m37.94    \u001b[39m | \u001b[39m123.7    \u001b[39m |\n| \u001b[39m3        \u001b[39m | \u001b[39m0.6667   \u001b[39m | \u001b[39m12.02    \u001b[39m | \u001b[39m39.64    \u001b[39m |\n| \u001b[39m4        \u001b[39m | \u001b[39m0.68     \u001b[39m | \u001b[39m7.614    \u001b[39m | \u001b[39m174.6    \u001b[39m |\n| \u001b[39m5        \u001b[39m | \u001b[39m0.71     \u001b[39m | \u001b[39m32.05    \u001b[39m | \u001b[39m144.5    \u001b[39m |\n| \u001b[35m6        \u001b[39m | \u001b[35m0.7167   \u001b[39m | \u001b[35m22.23    \u001b[39m | \u001b[35m189.4    \u001b[39m |\n| \u001b[35m7        \u001b[39m | \u001b[35m0.72     \u001b[39m | \u001b[35m30.85    \u001b[39m | \u001b[35m185.0    \u001b[39m |\n| \u001b[39m8        \u001b[39m | \u001b[39m0.7167   \u001b[39m | \u001b[39m33.23    \u001b[39m | \u001b[39m170.2    \u001b[39m |\n| \u001b[39m9        \u001b[39m | \u001b[39m0.71     \u001b[39m | \u001b[39m48.27    \u001b[39m | \u001b[39m176.6    \u001b[39m |\n| \u001b[39m10       \u001b[39m | \u001b[39m0.7133   \u001b[39m | \u001b[39m46.08    \u001b[39m | \u001b[39m157.5    \u001b[39m |\n| \u001b[39m11       \u001b[39m | \u001b[39m0.7133   \u001b[39m | \u001b[39m47.04    \u001b[39m | \u001b[39m199.0    \u001b[39m |\n| \u001b[39m12       \u001b[39m | \u001b[39m0.6267   \u001b[39m | \u001b[39m5.284    \u001b[39m | \u001b[39m99.61    \u001b[39m |\n| \u001b[39m13       \u001b[39m | \u001b[39m0.59     \u001b[39m | \u001b[39m49.46    \u001b[39m | \u001b[39m10.69    \u001b[39m |\n| \u001b[39m14       \u001b[39m | \u001b[39m0.7      \u001b[39m | \u001b[39m49.95    \u001b[39m | \u001b[39m86.17    \u001b[39m |\n| \u001b[39m15       \u001b[39m | \u001b[39m0.7067   \u001b[39m | \u001b[39m49.91    \u001b[39m | \u001b[39m133.7    \u001b[39m |\n| \u001b[39m16       \u001b[39m | \u001b[39m0.7      \u001b[39m | \u001b[39m49.87    \u001b[39m | \u001b[39m61.17    \u001b[39m |\n| \u001b[39m17       \u001b[39m | \u001b[39m0.71     \u001b[39m | \u001b[39m49.63    \u001b[39m | \u001b[39m110.2    \u001b[39m |\n| \u001b[39m18       \u001b[39m | \u001b[39m0.63     \u001b[39m | \u001b[39m5.313    \u001b[39m | \u001b[39m141.3    \u001b[39m |\n| \u001b[39m19       \u001b[39m | \u001b[39m0.7      \u001b[39m | \u001b[39m28.32    \u001b[39m | \u001b[39m68.56    \u001b[39m |\n| \u001b[39m20       \u001b[39m | \u001b[39m0.5733   \u001b[39m | \u001b[39m5.061    \u001b[39m | \u001b[39m10.27    \u001b[39m |\n| \u001b[39m21       \u001b[39m | \u001b[39m0.6267   \u001b[39m | \u001b[39m5.068    \u001b[39m | \u001b[39m60.53    \u001b[39m |\n| \u001b[39m22       \u001b[39m | \u001b[39m0.7      \u001b[39m | \u001b[39m34.4     \u001b[39m | \u001b[39m49.28    \u001b[39m |\n| \u001b[39m23       \u001b[39m | \u001b[39m0.7067   \u001b[39m | \u001b[39m35.69    \u001b[39m | \u001b[39m97.36    \u001b[39m |\n| \u001b[39m24       \u001b[39m | \u001b[39m0.7167   \u001b[39m | \u001b[39m24.09    \u001b[39m | \u001b[39m177.7    \u001b[39m |\n| \u001b[39m25       \u001b[39m | \u001b[39m0.71     \u001b[39m | \u001b[39m33.61    \u001b[39m | \u001b[39m157.0    \u001b[39m |\n| \u001b[39m26       \u001b[39m | \u001b[39m0.6967   \u001b[39m | \u001b[39m39.66    \u001b[39m | \u001b[39m75.43    \u001b[39m |\n| \u001b[39m27       \u001b[39m | \u001b[39m0.71     \u001b[39m | \u001b[39m43.03    \u001b[39m | \u001b[39m144.4    \u001b[39m |\n| \u001b[39m28       \u001b[39m | \u001b[39m0.7167   \u001b[39m | \u001b[39m49.72    \u001b[39m | \u001b[39m189.7    \u001b[39m |\n| \u001b[39m29       \u001b[39m | \u001b[39m0.7133   \u001b[39m | \u001b[39m40.67    \u001b[39m | \u001b[39m191.3    \u001b[39m |\n| \u001b[39m30       \u001b[39m | \u001b[39m0.7033   \u001b[39m | \u001b[39m49.18    \u001b[39m | \u001b[39m99.28    \u001b[39m |\n| \u001b[39m31       \u001b[39m | \u001b[39m0.6233   \u001b[39m | \u001b[39m5.209    \u001b[39m | \u001b[39m195.3    \u001b[39m |\n| \u001b[39m32       \u001b[39m | \u001b[39m0.7133   \u001b[39m | \u001b[39m33.77    \u001b[39m | \u001b[39m199.9    \u001b[39m |\n| \u001b[39m33       \u001b[39m | \u001b[39m0.7133   \u001b[39m | \u001b[39m37.44    \u001b[39m | \u001b[39m109.2    \u001b[39m |\n| \u001b[39m34       \u001b[39m | \u001b[39m0.7133   \u001b[39m | \u001b[39m28.48    \u001b[39m | \u001b[39m190.1    \u001b[39m |\n| \u001b[39m35       \u001b[39m | \u001b[39m0.6933   \u001b[39m | \u001b[39m49.88    \u001b[39m | \u001b[39m45.09    \u001b[39m |\n| \u001b[39m36       \u001b[39m | \u001b[39m0.7133   \u001b[39m | \u001b[39m37.45    \u001b[39m | \u001b[39m178.3    \u001b[39m |\n| \u001b[39m37       \u001b[39m | \u001b[39m0.7067   \u001b[39m | \u001b[39m49.97    \u001b[39m | \u001b[39m165.9    \u001b[39m |\n| \u001b[39m38       \u001b[39m | \u001b[39m0.7033   \u001b[39m | \u001b[39m49.67    \u001b[39m | \u001b[39m149.8    \u001b[39m |\n| \u001b[39m39       \u001b[39m | \u001b[39m0.7      \u001b[39m | \u001b[39m49.95    \u001b[39m | \u001b[39m120.7    \u001b[39m |\n| \u001b[39m40       \u001b[39m | \u001b[39m0.6967   \u001b[39m | \u001b[39m36.61    \u001b[39m | \u001b[39m60.54    \u001b[39m |\n| \u001b[39m41       \u001b[39m | \u001b[39m0.7067   \u001b[39m | \u001b[39m40.46    \u001b[39m | \u001b[39m164.9    \u001b[39m |\n| \u001b[39m42       \u001b[39m | \u001b[39m0.7067   \u001b[39m | \u001b[39m22.83    \u001b[39m | \u001b[39m164.0    \u001b[39m |\n| \u001b[39m43       \u001b[39m | \u001b[39m0.71     \u001b[39m | \u001b[39m27.08    \u001b[39m | \u001b[39m113.4    \u001b[39m |\n| \u001b[39m44       \u001b[39m | \u001b[39m0.7033   \u001b[39m | \u001b[39m27.08    \u001b[39m | \u001b[39m84.53    \u001b[39m |\n| \u001b[39m45       \u001b[39m | \u001b[39m0.7067   \u001b[39m | \u001b[39m26.33    \u001b[39m | \u001b[39m128.9    \u001b[39m |\n| \u001b[39m46       \u001b[39m | \u001b[39m0.71     \u001b[39m | \u001b[39m35.57    \u001b[39m | \u001b[39m136.0    \u001b[39m |\n| \u001b[39m47       \u001b[39m | \u001b[39m0.7167   \u001b[39m | \u001b[39m25.82    \u001b[39m | \u001b[39m183.4    \u001b[39m |\n| \u001b[39m48       \u001b[39m | \u001b[39m0.7067   \u001b[39m | \u001b[39m27.47    \u001b[39m | \u001b[39m102.2    \u001b[39m |\n| \u001b[39m49       \u001b[39m | \u001b[39m0.7167   \u001b[39m | \u001b[39m27.02    \u001b[39m | \u001b[39m171.6    \u001b[39m |\n| \u001b[39m50       \u001b[39m | \u001b[39m0.7033   \u001b[39m | \u001b[39m17.79    \u001b[39m | \u001b[39m182.9    \u001b[39m |\n| \u001b[39m51       \u001b[39m | \u001b[39m0.6767   \u001b[39m | \u001b[39m31.79    \u001b[39m | \u001b[39m36.83    \u001b[39m |\n| \u001b[39m52       \u001b[39m | \u001b[39m0.7167   \u001b[39m | \u001b[39m30.55    \u001b[39m | \u001b[39m177.6    \u001b[39m |\n| \u001b[39m53       \u001b[39m | \u001b[39m0.7133   \u001b[39m | \u001b[39m49.83    \u001b[39m | \u001b[39m182.9    \u001b[39m |\n| \u001b[39m54       \u001b[39m | \u001b[39m0.71     \u001b[39m | \u001b[39m39.26    \u001b[39m | \u001b[39m151.7    \u001b[39m |\n| \u001b[39m55       \u001b[39m | \u001b[39m0.7133   \u001b[39m | \u001b[39m40.44    \u001b[39m | \u001b[39m200.0    \u001b[39m |\n=================================================\nHyperparameters tuning time: 37.666 seconds\nMeilleurs hyperparamètres : {'target': 0.72, 'params': {'max_depth': 30.84676238953326, 'n_estimators': 184.9594453578212}}\nTraining time: 0.191 seconds\nTest (prediction) time: 0.037 seconds\nRapport de classification :\n               precision    recall  f1-score   support\n\n       blues       0.76      0.63      0.69        30\n   classical       0.82      0.93      0.87        30\n     country       0.75      0.80      0.77        30\n       disco       0.56      0.60      0.58        30\n      hiphop       0.58      0.63      0.60        30\n        jazz       0.79      0.87      0.83        30\n       metal       0.80      0.80      0.80        30\n         pop       0.80      0.80      0.80        30\n      reggae       0.63      0.63      0.63        30\n        rock       0.48      0.33      0.39        30\n\n    accuracy                           0.70       300\n   macro avg       0.70      0.70      0.70       300\nweighted avg       0.70      0.70      0.70       300\n\nMatrice de confusion :\n [[19  0  2  3  1  0  0  0  4  1]\n [ 0 28  0  0  0  1  0  0  0  1]\n [ 1  1 24  0  0  1  0  0  0  3]\n [ 0  1  1 18  4  0  1  4  1  0]\n [ 1  0  0  5 19  0  0  1  3  1]\n [ 0  4  0  0  0 26  0  0  0  0]\n [ 2  0  0  1  2  0 24  0  0  1]\n [ 0  0  1  1  3  0  0 24  1  0]\n [ 0  0  1  1  3  1  0  1 19  4]\n [ 2  0  3  3  1  4  5  0  2 10]]\n","output_type":"stream"}],"execution_count":21},{"cell_type":"code","source":"# Import necessary libraries\nimport pandas as pd\nimport time\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.metrics import classification_report, confusion_matrix\nfrom bayes_opt import BayesianOptimization\nfrom xgboost import XGBClassifier\n\nX = df.drop(columns=['label'])  # Supprime la colonne cible\ny = df['label']\n\n# Encoder la variable cible\nencoder = LabelEncoder()\ny = encoder.fit_transform(y)\n\n# Diviser les données en ensembles d'entraînement et de test\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42, stratify=y)\n\n# Function for Bayesian Optimization with XGBoost\ndef optimize_xgb(n_estimators, max_depth, learning_rate):\n    # Convert float parameters to integers where necessary\n    n_estimators = int(n_estimators)\n    max_depth = int(max_depth)\n\n    model = XGBClassifier(\n        n_estimators=n_estimators,\n        max_depth=max_depth,\n        learning_rate=learning_rate,\n        objective='multi:softmax',\n        eval_metric='mlogloss',\n        use_label_encoder=False,\n        random_state=42,\n        n_jobs=-1\n    )\n    model.fit(X_train, y_train)\n    return model.score(X_test, y_test)\n\n# Define parameter bounds for XGBoost\nparam_bounds_xgb = {\n    'n_estimators': (10, 200),\n    'max_depth': (3, 20),\n    'learning_rate': (0.01, 0.3)\n}\n\n# Run Bayesian Optimization\noptimizer_xgb = BayesianOptimization(f=optimize_xgb, pbounds=param_bounds_xgb, random_state=42)\nstart_opt = time.time_ns()\noptimizer_xgb.maximize(init_points=5, n_iter=50)\nend_opt = time.time_ns()\nopt_time = (end_opt - start_opt) / 1e9  # Convert nanoseconds to seconds\n\nprint(f\"Hyperparameters tuning time: {opt_time:.3f} seconds\")\n\n# Extract the best parameters\nbest_params_xgb = optimizer_xgb.max['params']\nbest_params_xgb['n_estimators'] = int(best_params_xgb['n_estimators'])\nbest_params_xgb['max_depth'] = int(best_params_xgb['max_depth'])\nprint(\"Meilleurs hyperparamètres :\", best_params_xgb)\n\n# Train the model with the best hyperparameters\nbest_model_xgb = XGBClassifier(\n    n_estimators=best_params_xgb['n_estimators'],\n    max_depth=best_params_xgb['max_depth'],\n    learning_rate=best_params_xgb['learning_rate'],\n    objective='multi:softmax',\n    eval_metric='mlogloss',\n    use_label_encoder=False,\n    random_state=42,\n    n_jobs=-1\n)\n\nstart_train = time.time_ns()\nbest_model_xgb.fit(X_train, y_train)\nend_train = time.time_ns()\ntrain_time = (end_train - start_train) / 1e9  # Convert nanoseconds to seconds\nprint(f\"Training time: {train_time:.3f} seconds\")\n\n# Model evaluation\nstart_test = time.time_ns()\ny_pred_xgb = best_model_xgb.predict(X_test)\nend_test = time.time_ns()\ntest_time = (end_test - start_test) / 1e9  # Convert nanoseconds to seconds\nprint(f\"Test (prediction) time: {test_time:.3f} seconds\")\n\n# Rapport de classification\nprint(\"Rapport de classification :\\n\", classification_report(y_test, y_pred_xgb, target_names=encoder.classes_))\n\n# Confusion matrix\nconf_matrix_xgb = confusion_matrix(y_test, y_pred_xgb)\nprint(\"Matrice de confusion :\\n\", conf_matrix_xgb)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-16T02:50:57.415778Z","iopub.execute_input":"2025-02-16T02:50:57.416042Z","iopub.status.idle":"2025-02-16T02:53:22.840562Z","shell.execute_reply.started":"2025-02-16T02:50:57.416018Z","shell.execute_reply":"2025-02-16T02:53:22.839367Z"}},"outputs":[{"name":"stdout","text":"|   iter    |  target   | learni... | max_depth | n_esti... |\n-------------------------------------------------------------\n| \u001b[39m1        \u001b[39m | \u001b[39m0.7233   \u001b[39m | \u001b[39m0.1186   \u001b[39m | \u001b[39m19.16    \u001b[39m | \u001b[39m149.1    \u001b[39m |\n| \u001b[39m2        \u001b[39m | \u001b[39m0.7033   \u001b[39m | \u001b[39m0.1836   \u001b[39m | \u001b[39m5.652    \u001b[39m | \u001b[39m39.64    \u001b[39m |\n| \u001b[39m3        \u001b[39m | \u001b[39m0.6667   \u001b[39m | \u001b[39m0.02684  \u001b[39m | \u001b[39m17.72    \u001b[39m | \u001b[39m124.2    \u001b[39m |\n| \u001b[35m4        \u001b[39m | \u001b[35m0.7267   \u001b[39m | \u001b[35m0.2153   \u001b[39m | \u001b[35m3.35     \u001b[39m | \u001b[35m194.3    \u001b[39m |\n| \u001b[39m5        \u001b[39m | \u001b[39m0.7      \u001b[39m | \u001b[39m0.2514   \u001b[39m | \u001b[39m6.61     \u001b[39m | \u001b[39m44.55    \u001b[39m |\n| \u001b[39m6        \u001b[39m | \u001b[39m0.71     \u001b[39m | \u001b[39m0.1483   \u001b[39m | \u001b[39m9.617    \u001b[39m | \u001b[39m178.6    \u001b[39m |\n| \u001b[39m7        \u001b[39m | \u001b[39m0.6833   \u001b[39m | \u001b[39m0.2923   \u001b[39m | \u001b[39m16.54    \u001b[39m | \u001b[39m199.9    \u001b[39m |\n| \u001b[39m8        \u001b[39m | \u001b[39m0.6667   \u001b[39m | \u001b[39m0.01609  \u001b[39m | \u001b[39m3.118    \u001b[39m | \u001b[39m187.0    \u001b[39m |\n| \u001b[39m9        \u001b[39m | \u001b[39m0.7233   \u001b[39m | \u001b[39m0.1563   \u001b[39m | \u001b[39m3.33     \u001b[39m | \u001b[39m193.2    \u001b[39m |\n| \u001b[39m10       \u001b[39m | \u001b[39m0.6933   \u001b[39m | \u001b[39m0.02991  \u001b[39m | \u001b[39m7.398    \u001b[39m | \u001b[39m195.2    \u001b[39m |\n| \u001b[39m11       \u001b[39m | \u001b[39m0.7033   \u001b[39m | \u001b[39m0.1669   \u001b[39m | \u001b[39m15.69    \u001b[39m | \u001b[39m149.6    \u001b[39m |\n| \u001b[39m12       \u001b[39m | \u001b[39m0.7167   \u001b[39m | \u001b[39m0.2297   \u001b[39m | \u001b[39m19.96    \u001b[39m | \u001b[39m145.9    \u001b[39m |\n| \u001b[39m13       \u001b[39m | \u001b[39m0.7167   \u001b[39m | \u001b[39m0.2161   \u001b[39m | \u001b[39m19.67    \u001b[39m | \u001b[39m153.1    \u001b[39m |\n| \u001b[35m14       \u001b[39m | \u001b[35m0.73     \u001b[39m | \u001b[35m0.2621   \u001b[39m | \u001b[35m3.167    \u001b[39m | \u001b[35m198.9    \u001b[39m |\n| \u001b[39m15       \u001b[39m | \u001b[39m0.7067   \u001b[39m | \u001b[39m0.2619   \u001b[39m | \u001b[39m14.43    \u001b[39m | \u001b[39m172.2    \u001b[39m |\n| \u001b[39m16       \u001b[39m | \u001b[39m0.7133   \u001b[39m | \u001b[39m0.1606   \u001b[39m | \u001b[39m19.99    \u001b[39m | \u001b[39m161.1    \u001b[39m |\n| \u001b[39m17       \u001b[39m | \u001b[39m0.72     \u001b[39m | \u001b[39m0.1283   \u001b[39m | \u001b[39m13.04    \u001b[39m | \u001b[39m162.4    \u001b[39m |\n| \u001b[39m18       \u001b[39m | \u001b[39m0.7033   \u001b[39m | \u001b[39m0.2713   \u001b[39m | \u001b[39m7.301    \u001b[39m | \u001b[39m164.0    \u001b[39m |\n| \u001b[39m19       \u001b[39m | \u001b[39m0.7067   \u001b[39m | \u001b[39m0.04774  \u001b[39m | \u001b[39m14.41    \u001b[39m | \u001b[39m157.8    \u001b[39m |\n| \u001b[39m20       \u001b[39m | \u001b[39m0.71     \u001b[39m | \u001b[39m0.2956   \u001b[39m | \u001b[39m16.6     \u001b[39m | \u001b[39m166.2    \u001b[39m |\n| \u001b[39m21       \u001b[39m | \u001b[39m0.6967   \u001b[39m | \u001b[39m0.2403   \u001b[39m | \u001b[39m18.58    \u001b[39m | \u001b[39m180.9    \u001b[39m |\n| \u001b[39m22       \u001b[39m | \u001b[39m0.73     \u001b[39m | \u001b[39m0.2313   \u001b[39m | \u001b[39m3.368    \u001b[39m | \u001b[39m84.08    \u001b[39m |\n| \u001b[39m23       \u001b[39m | \u001b[39m0.7067   \u001b[39m | \u001b[39m0.1076   \u001b[39m | \u001b[39m7.243    \u001b[39m | \u001b[39m82.59    \u001b[39m |\n| \u001b[39m24       \u001b[39m | \u001b[39m0.7067   \u001b[39m | \u001b[39m0.1011   \u001b[39m | \u001b[39m3.063    \u001b[39m | \u001b[39m87.14    \u001b[39m |\n| \u001b[39m25       \u001b[39m | \u001b[39m0.7267   \u001b[39m | \u001b[39m0.2989   \u001b[39m | \u001b[39m3.503    \u001b[39m | \u001b[39m81.38    \u001b[39m |\n| \u001b[39m26       \u001b[39m | \u001b[39m0.72     \u001b[39m | \u001b[39m0.1255   \u001b[39m | \u001b[39m3.085    \u001b[39m | \u001b[39m76.78    \u001b[39m |\n| \u001b[39m27       \u001b[39m | \u001b[39m0.7233   \u001b[39m | \u001b[39m0.1501   \u001b[39m | \u001b[39m3.291    \u001b[39m | \u001b[39m71.45    \u001b[39m |\n| \u001b[39m28       \u001b[39m | \u001b[39m0.72     \u001b[39m | \u001b[39m0.1784   \u001b[39m | \u001b[39m7.613    \u001b[39m | \u001b[39m72.38    \u001b[39m |\n| \u001b[39m29       \u001b[39m | \u001b[39m0.72     \u001b[39m | \u001b[39m0.1442   \u001b[39m | \u001b[39m6.266    \u001b[39m | \u001b[39m67.37    \u001b[39m |\n| \u001b[39m30       \u001b[39m | \u001b[39m0.7033   \u001b[39m | \u001b[39m0.2494   \u001b[39m | \u001b[39m12.36    \u001b[39m | \u001b[39m68.3     \u001b[39m |\n| \u001b[39m31       \u001b[39m | \u001b[39m0.7033   \u001b[39m | \u001b[39m0.1288   \u001b[39m | \u001b[39m3.098    \u001b[39m | \u001b[39m62.11    \u001b[39m |\n| \u001b[39m32       \u001b[39m | \u001b[39m0.6433   \u001b[39m | \u001b[39m0.1014   \u001b[39m | \u001b[39m19.28    \u001b[39m | \u001b[39m10.04    \u001b[39m |\n| \u001b[39m33       \u001b[39m | \u001b[39m0.7267   \u001b[39m | \u001b[39m0.179    \u001b[39m | \u001b[39m19.8     \u001b[39m | \u001b[39m99.69    \u001b[39m |\n| \u001b[39m34       \u001b[39m | \u001b[39m0.7133   \u001b[39m | \u001b[39m0.2101   \u001b[39m | \u001b[39m15.18    \u001b[39m | \u001b[39m103.7    \u001b[39m |\n| \u001b[39m35       \u001b[39m | \u001b[39m0.7      \u001b[39m | \u001b[39m0.2836   \u001b[39m | \u001b[39m19.71    \u001b[39m | \u001b[39m93.74    \u001b[39m |\n| \u001b[39m36       \u001b[39m | \u001b[39m0.7133   \u001b[39m | \u001b[39m0.1873   \u001b[39m | \u001b[39m19.84    \u001b[39m | \u001b[39m107.1    \u001b[39m |\n| \u001b[39m37       \u001b[39m | \u001b[39m0.7133   \u001b[39m | \u001b[39m0.1561   \u001b[39m | \u001b[39m3.122    \u001b[39m | \u001b[39m109.0    \u001b[39m |\n| \u001b[35m38       \u001b[39m | \u001b[35m0.7333   \u001b[39m | \u001b[35m0.1076   \u001b[39m | \u001b[35m3.126    \u001b[39m | \u001b[35m118.6    \u001b[39m |\n| \u001b[39m39       \u001b[39m | \u001b[39m0.7233   \u001b[39m | \u001b[39m0.2461   \u001b[39m | \u001b[39m3.07     \u001b[39m | \u001b[39m123.6    \u001b[39m |\n| \u001b[39m40       \u001b[39m | \u001b[39m0.7333   \u001b[39m | \u001b[39m0.1986   \u001b[39m | \u001b[39m7.08     \u001b[39m | \u001b[39m116.3    \u001b[39m |\n| \u001b[39m41       \u001b[39m | \u001b[39m0.6867   \u001b[39m | \u001b[39m0.03529  \u001b[39m | \u001b[39m7.887    \u001b[39m | \u001b[39m120.7    \u001b[39m |\n| \u001b[39m42       \u001b[39m | \u001b[39m0.7133   \u001b[39m | \u001b[39m0.2337   \u001b[39m | \u001b[39m3.868    \u001b[39m | \u001b[39m114.8    \u001b[39m |\n| \u001b[39m43       \u001b[39m | \u001b[39m0.7167   \u001b[39m | \u001b[39m0.2236   \u001b[39m | \u001b[39m8.77     \u001b[39m | \u001b[39m113.5    \u001b[39m |\n| \u001b[39m44       \u001b[39m | \u001b[39m0.7033   \u001b[39m | \u001b[39m0.06872  \u001b[39m | \u001b[39m16.01    \u001b[39m | \u001b[39m98.71    \u001b[39m |\n| \u001b[39m45       \u001b[39m | \u001b[39m0.6967   \u001b[39m | \u001b[39m0.2582   \u001b[39m | \u001b[39m19.06    \u001b[39m | \u001b[39m102.8    \u001b[39m |\n| \u001b[39m46       \u001b[39m | \u001b[39m0.7167   \u001b[39m | \u001b[39m0.06665  \u001b[39m | \u001b[39m5.737    \u001b[39m | \u001b[39m117.5    \u001b[39m |\n| \u001b[39m47       \u001b[39m | \u001b[39m0.7333   \u001b[39m | \u001b[39m0.2552   \u001b[39m | \u001b[39m3.072    \u001b[39m | \u001b[39m121.0    \u001b[39m |\n| \u001b[39m48       \u001b[39m | \u001b[39m0.6967   \u001b[39m | \u001b[39m0.08804  \u001b[39m | \u001b[39m10.03    \u001b[39m | \u001b[39m116.1    \u001b[39m |\n| \u001b[39m49       \u001b[39m | \u001b[39m0.7133   \u001b[39m | \u001b[39m0.2679   \u001b[39m | \u001b[39m4.745    \u001b[39m | \u001b[39m74.15    \u001b[39m |\n| \u001b[39m50       \u001b[39m | \u001b[39m0.73     \u001b[39m | \u001b[39m0.1383   \u001b[39m | \u001b[39m3.008    \u001b[39m | \u001b[39m196.8    \u001b[39m |\n| \u001b[39m51       \u001b[39m | \u001b[39m0.6933   \u001b[39m | \u001b[39m0.09248  \u001b[39m | \u001b[39m3.06     \u001b[39m | \u001b[39m68.29    \u001b[39m |\n| \u001b[39m52       \u001b[39m | \u001b[39m0.72     \u001b[39m | \u001b[39m0.2617   \u001b[39m | \u001b[39m6.434    \u001b[39m | \u001b[39m114.1    \u001b[39m |\n| \u001b[39m53       \u001b[39m | \u001b[39m0.73     \u001b[39m | \u001b[39m0.1605   \u001b[39m | \u001b[39m5.406    \u001b[39m | \u001b[39m199.9    \u001b[39m |\n| \u001b[39m54       \u001b[39m | \u001b[39m0.7067   \u001b[39m | \u001b[39m0.1561   \u001b[39m | \u001b[39m7.973    \u001b[39m | \u001b[39m64.34    \u001b[39m |\n| \u001b[39m55       \u001b[39m | \u001b[39m0.66     \u001b[39m | \u001b[39m0.03855  \u001b[39m | \u001b[39m7.811    \u001b[39m | \u001b[39m69.57    \u001b[39m |\n=============================================================\nHyperparameters tuning time: 143.345 seconds\nMeilleurs hyperparamètres : {'learning_rate': 0.10759308525006839, 'max_depth': 3, 'n_estimators': 118}\nTraining time: 1.781 seconds\nTest (prediction) time: 0.010 seconds\nRapport de classification :\n               precision    recall  f1-score   support\n\n       blues       0.75      0.60      0.67        30\n   classical       0.91      0.97      0.94        30\n     country       0.66      0.83      0.74        30\n       disco       0.67      0.67      0.67        30\n      hiphop       0.57      0.77      0.66        30\n        jazz       0.87      0.90      0.89        30\n       metal       0.91      0.67      0.77        30\n         pop       0.90      0.87      0.88        30\n      reggae       0.65      0.57      0.61        30\n        rock       0.54      0.50      0.52        30\n\n    accuracy                           0.73       300\n   macro avg       0.74      0.73      0.73       300\nweighted avg       0.74      0.73      0.73       300\n\nMatrice de confusion :\n [[18  0  4  0  3  0  2  0  2  1]\n [ 0 29  0  0  0  1  0  0  0  0]\n [ 0  0 25  1  0  1  0  0  1  2]\n [ 0  0  2 20  5  0  0  2  1  0]\n [ 1  0  0  3 23  0  0  1  1  1]\n [ 0  3  0  0  0 27  0  0  0  0]\n [ 2  0  0  1  4  0 20  0  1  2]\n [ 0  0  1  1  1  0  0 26  1  0]\n [ 0  0  2  1  3  0  0  0 17  7]\n [ 3  0  4  3  1  2  0  0  2 15]]\n","output_type":"stream"}],"execution_count":22},{"cell_type":"code","source":"df = pd.read_csv(\"/kaggle/input/gtzan-dataset-music-genre-classification/Data/features_3_sec.csv\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-16T02:53:22.841487Z","iopub.execute_input":"2025-02-16T02:53:22.841772Z","iopub.status.idle":"2025-02-16T02:53:23.151356Z","shell.execute_reply.started":"2025-02-16T02:53:22.841746Z","shell.execute_reply":"2025-02-16T02:53:23.150285Z"}},"outputs":[],"execution_count":23},{"cell_type":"code","source":"df.drop(columns=['filename', 'length'], inplace=True)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-16T02:53:23.152338Z","iopub.execute_input":"2025-02-16T02:53:23.152646Z","iopub.status.idle":"2025-02-16T02:53:23.158703Z","shell.execute_reply.started":"2025-02-16T02:53:23.152619Z","shell.execute_reply":"2025-02-16T02:53:23.157716Z"}},"outputs":[],"execution_count":24},{"cell_type":"code","source":"from sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import LabelEncoder, StandardScaler\nfrom sklearn.svm import SVC\nfrom sklearn.metrics import classification_report, confusion_matrix, roc_auc_score, RocCurveDisplay\nfrom bayes_opt import BayesianOptimization\nimport numpy as np\nimport matplotlib.pyplot as plt\n\n# Prétraitement des données\nX = df.drop(columns=['label'])  # Supprimez les colonnes non pertinentes\ny = df['label']\n\n# Encoder la variable cible\nencoder = LabelEncoder()\ny = encoder.fit_transform(y)\n\n# Normaliser les données\nscaler = StandardScaler()\nX_scaled = scaler.fit_transform(X)\n\n# Diviser les données en ensembles d'entraînement et de test\nX_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.2, random_state=42, stratify=y)\n\n# Fonction d'évaluation pour BayesianOptimization\ndef optimize_svm(C, gamma):\n    model = SVC(C=C, gamma=gamma, kernel='rbf', probability=True, random_state=42)\n    model.fit(X_train, y_train)\n    return model.score(X_test, y_test)\n\n# Définir les limites des hyperparamètres\nparam_bounds = {\n    'C': (0.1, 100),      # Paramètre de régularisation\n    'gamma': (1e-4, 1e-1) # Coefficient pour le noyau RBF\n}\n\n# Lancer l'optimisation\noptimizer = BayesianOptimization(f=optimize_svm, pbounds=param_bounds, random_state=42)\nstart_opt = time.time_ns()\noptimizer.maximize(init_points=5, n_iter=20)\nend_opt = time.time_ns()\nopt_time = (end_opt - start_opt) / 1e9  # Convert nanoseconds to seconds\n\nprint(f\"Hyperparameters tuning time: {opt_time:.3f} seconds\")\n\n\n# Extraire les meilleurs hyperparamètres\nbest_params = optimizer.max\nprint(\"Meilleurs hyperparamètres :\", best_params)\n\n# Entraîner le modèle avec les meilleurs hyperparamètres\nbest_model_3sec = SVC(C=best_params['params']['C'], gamma=best_params['params']['gamma'], kernel='rbf', probability=True, random_state=42)\n# Training time\nstart_train = time.time_ns()\nbest_model_3sec.fit(X_train, y_train)\nend_train = time.time_ns()\ntrain_time = (end_train - start_train) / 1e9  # Convert nanoseconds to seconds\nprint(f\"Training time: {train_time:.3f} seconds\")\n\n\n# Test (prediction) time\nstart_test = time.time_ns()\ny_pred = best_model_3sec.predict(X_test)\nend_test = time.time_ns()\ntest_time = (end_test - start_test) / 1e9  # Convert nanoseconds to seconds\nprint(f\"Test (prediction) time: {test_time:.3f} seconds\")\n\n\nprint(\"Rapport de classification :\\n\", classification_report(y_test, y_pred, target_names=encoder.classes_))\n\n# Matrice de confusion\nconf_matrix = confusion_matrix(y_test, y_pred)\nprint(\"Matrice de confusion :\\n\", conf_matrix)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-16T02:53:23.159803Z","iopub.execute_input":"2025-02-16T02:53:23.160203Z","iopub.status.idle":"2025-02-16T03:04:47.417988Z","shell.execute_reply.started":"2025-02-16T02:53:23.160163Z","shell.execute_reply":"2025-02-16T03:04:47.416851Z"}},"outputs":[{"name":"stdout","text":"|   iter    |  target   |     C     |   gamma   |\n-------------------------------------------------\n| \u001b[39m1        \u001b[39m | \u001b[39m0.8699   \u001b[39m | \u001b[39m37.52    \u001b[39m | \u001b[39m0.09508  \u001b[39m |\n| \u001b[35m2        \u001b[39m | \u001b[35m0.9044   \u001b[39m | \u001b[35m73.23    \u001b[39m | \u001b[35m0.05991  \u001b[39m |\n| \u001b[35m3        \u001b[39m | \u001b[35m0.9129   \u001b[39m | \u001b[35m15.69    \u001b[39m | \u001b[35m0.01568  \u001b[39m |\n| \u001b[39m4        \u001b[39m | \u001b[39m0.8789   \u001b[39m | \u001b[39m5.903    \u001b[39m | \u001b[39m0.08663  \u001b[39m |\n| \u001b[39m5        \u001b[39m | \u001b[39m0.8934   \u001b[39m | \u001b[39m60.15    \u001b[39m | \u001b[39m0.07084  \u001b[39m |\n| \u001b[39m6        \u001b[39m | \u001b[39m0.8914   \u001b[39m | \u001b[39m15.72    \u001b[39m | \u001b[39m0.07382  \u001b[39m |\n| \u001b[35m7        \u001b[39m | \u001b[35m0.9159   \u001b[39m | \u001b[35m82.86    \u001b[39m | \u001b[35m0.0301   \u001b[39m |\n| \u001b[39m8        \u001b[39m | \u001b[39m0.9119   \u001b[39m | \u001b[39m10.23    \u001b[39m | \u001b[39m0.05221  \u001b[39m |\n| \u001b[39m9        \u001b[39m | \u001b[39m0.8649   \u001b[39m | \u001b[39m0.6638   \u001b[39m | \u001b[39m0.04643  \u001b[39m |\n| \u001b[39m10       \u001b[39m | \u001b[39m0.9024   \u001b[39m | \u001b[39m66.79    \u001b[39m | \u001b[39m0.06425  \u001b[39m |\n| \u001b[39m11       \u001b[39m | \u001b[39m0.9074   \u001b[39m | \u001b[39m3.344    \u001b[39m | \u001b[39m0.0216   \u001b[39m |\n| \u001b[39m12       \u001b[39m | \u001b[39m0.8814   \u001b[39m | \u001b[39m44.24    \u001b[39m | \u001b[39m0.08245  \u001b[39m |\n| \u001b[39m13       \u001b[39m | \u001b[39m0.9109   \u001b[39m | \u001b[39m1.96     \u001b[39m | \u001b[39m0.04389  \u001b[39m |\n| \u001b[39m14       \u001b[39m | \u001b[39m0.9134   \u001b[39m | \u001b[39m39.57    \u001b[39m | \u001b[39m0.04879  \u001b[39m |\n| \u001b[39m15       \u001b[39m | \u001b[39m0.9089   \u001b[39m | \u001b[39m69.05    \u001b[39m | \u001b[39m0.01233  \u001b[39m |\n| \u001b[39m16       \u001b[39m | \u001b[39m0.9134   \u001b[39m | \u001b[39m60.45    \u001b[39m | \u001b[39m0.01525  \u001b[39m |\n| \u001b[39m17       \u001b[39m | \u001b[39m0.8774   \u001b[39m | \u001b[39m79.3     \u001b[39m | \u001b[39m0.08841  \u001b[39m |\n| \u001b[39m18       \u001b[39m | \u001b[39m0.9124   \u001b[39m | \u001b[39m42.0     \u001b[39m | \u001b[39m0.01663  \u001b[39m |\n| \u001b[35m19       \u001b[39m | \u001b[35m0.9164   \u001b[39m | \u001b[35m11.59    \u001b[39m | \u001b[35m0.01993  \u001b[39m |\n| \u001b[39m20       \u001b[39m | \u001b[39m0.9154   \u001b[39m | \u001b[39m95.55    \u001b[39m | \u001b[39m0.02622  \u001b[39m |\n| \u001b[39m21       \u001b[39m | \u001b[39m0.8839   \u001b[39m | \u001b[39m81.37    \u001b[39m | \u001b[39m0.08024  \u001b[39m |\n| \u001b[39m22       \u001b[39m | \u001b[39m0.8869   \u001b[39m | \u001b[39m20.91    \u001b[39m | \u001b[39m0.07753  \u001b[39m |\n| \u001b[39m23       \u001b[39m | \u001b[39m0.8989   \u001b[39m | \u001b[39m81.94    \u001b[39m | \u001b[39m0.06811  \u001b[39m |\n| \u001b[39m24       \u001b[39m | \u001b[39m0.9004   \u001b[39m | \u001b[39m50.26    \u001b[39m | \u001b[39m0.06722  \u001b[39m |\n| \u001b[39m25       \u001b[39m | \u001b[39m0.8879   \u001b[39m | \u001b[39m63.5     \u001b[39m | \u001b[39m0.07656  \u001b[39m |\n=================================================\nHyperparameters tuning time: 670.319 seconds\nMeilleurs hyperparamètres : {'target': 0.9164164164164165, 'params': {'C': 11.585298046220824, 'gamma': 0.019929972280492453}}\nTraining time: 12.902 seconds\nTest (prediction) time: 0.976 seconds\nRapport de classification :\n               precision    recall  f1-score   support\n\n       blues       0.92      0.93      0.92       200\n   classical       0.90      0.98      0.94       199\n     country       0.87      0.87      0.87       199\n       disco       0.92      0.86      0.89       200\n      hiphop       0.92      0.92      0.92       200\n        jazz       0.92      0.94      0.93       200\n       metal       0.97      0.96      0.97       200\n         pop       0.94      0.88      0.91       200\n      reggae       0.90      0.92      0.91       200\n        rock       0.90      0.90      0.90       200\n\n    accuracy                           0.92      1998\n   macro avg       0.92      0.92      0.92      1998\nweighted avg       0.92      0.92      0.92      1998\n\nMatrice de confusion :\n [[185   3   3   1   1   2   1   0   3   1]\n [  0 195   1   0   0   2   0   0   0   1]\n [  8   1 174   0   0   4   0   3   4   5]\n [  0   1   4 173   4   1   4   4   4   5]\n [  0   1   3   3 184   0   1   3   4   1]\n [  3   9   1   0   0 187   0   0   0   0]\n [  0   0   0   3   1   0 193   0   1   2]\n [  0   4   2   6   4   1   0 176   4   3]\n [  2   2   4   0   4   2   0   1 184   1]\n [  3   0   9   3   1   4   0   0   0 180]]\n","output_type":"stream"}],"execution_count":25},{"cell_type":"code","source":"from sklearn.linear_model import LogisticRegression\nfrom sklearn.metrics import classification_report, confusion_matrix, roc_auc_score, RocCurveDisplay\nfrom bayes_opt import BayesianOptimization\nimport numpy as np\nimport matplotlib.pyplot as plt\n\n# Prétraitement des données\nX = df.drop(columns=['label'])  # Supprimez les colonnes non pertinentes\ny = df['label']\n\n# Encoder la variable cible\nencoder = LabelEncoder()\ny = encoder.fit_transform(y)\n\n# Normaliser les données\nscaler = StandardScaler()\nX_scaled = scaler.fit_transform(X)\n\n# Diviser les données en ensembles d'entraînement et de test\nX_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.2, random_state=42, stratify=y)\n\n# Fonction d'évaluation pour BayesianOptimization\ndef optimize_logistic_regression(C, tol):\n    model = LogisticRegression(C=C, tol=tol, max_iter=500, random_state=42)\n    model.fit(X_train, y_train)\n    return model.score(X_test, y_test)\n\n# Définir les limites des hyperparamètres\nparam_bounds = {\n    'C': (0.001, 10),\n    'tol': (1e-6, 1e-2)\n}\n\n# Lancer l'optimisation\noptimizer = BayesianOptimization(f=optimize_logistic_regression, pbounds=param_bounds, random_state=42)\nstart_opt = time.time_ns()\noptimizer.maximize(init_points=5, n_iter=20)\nend_opt = time.time_ns()\nopt_time = (end_opt - start_opt) / 1e9  # Convert nanoseconds to seconds\n\nprint(f\"Hyperparameters tuning time: {opt_time:.3f} seconds\")\n\n# Extraire les meilleurs hyperparamètres\nbest_params = optimizer.max\nprint(\"Meilleurs hyperparamètres :\", best_params)\n\n# Entraîner le modèle avec les meilleurs hyperparamètres\nbest_model = LogisticRegression(C=best_params['params']['C'], tol=best_params['params']['tol'], max_iter=500, random_state=42)\nstart_train = time.time_ns()\nbest_model.fit(X_train, y_train)\nend_train = time.time_ns()\ntrain_time = (end_train - start_train) / 1e9  # Convert nanoseconds to seconds\nprint(f\"Training time: {train_time:.3f} seconds\")\n\n# Évaluation du modèle\n# Test (prediction) time\nstart_test = time.time_ns()\ny_pred = best_model.predict(X_test)\nend_test = time.time_ns()\ntest_time = (end_test - start_test) / 1e9  # Convert nanoseconds to seconds\nprint(f\"Test (prediction) time: {test_time:.3f} seconds\")\nprint(\"Rapport de classification :\\n\", classification_report(y_test, y_pred, target_names=encoder.classes_))\n\n# Matrice de confusion\nconf_matrix = confusion_matrix(y_test, y_pred)\nprint(\"Matrice de confusion :\\n\", conf_matrix)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-16T03:04:47.419158Z","iopub.execute_input":"2025-02-16T03:04:47.419459Z","iopub.status.idle":"2025-02-16T03:05:24.404446Z","shell.execute_reply.started":"2025-02-16T03:04:47.419422Z","shell.execute_reply":"2025-02-16T03:05:24.403487Z"}},"outputs":[{"name":"stdout","text":"|   iter    |  target   |     C     |    tol    |\n-------------------------------------------------\n| \u001b[39m1        \u001b[39m | \u001b[39m0.7217   \u001b[39m | \u001b[39m3.746    \u001b[39m | \u001b[39m0.009507 \u001b[39m |\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\nSTOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n\nIncrease the number of iterations (max_iter) or scale the data as shown in:\n    https://scikit-learn.org/stable/modules/preprocessing.html\nPlease also refer to the documentation for alternative solver options:\n    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n  n_iter_i = _check_optimize_result(\n","output_type":"stream"},{"name":"stdout","text":"| \u001b[35m2        \u001b[39m | \u001b[35m0.7242   \u001b[39m | \u001b[35m7.32     \u001b[39m | \u001b[35m0.005987 \u001b[39m |\n| \u001b[39m3        \u001b[39m | \u001b[39m0.7217   \u001b[39m | \u001b[39m1.561    \u001b[39m | \u001b[39m0.001561 \u001b[39m |\n| \u001b[39m4        \u001b[39m | \u001b[39m0.7127   \u001b[39m | \u001b[39m0.5818   \u001b[39m | \u001b[39m0.008662 \u001b[39m |\n| \u001b[39m5        \u001b[39m | \u001b[39m0.7222   \u001b[39m | \u001b[39m6.012    \u001b[39m | \u001b[39m0.007081 \u001b[39m |\n| \u001b[39m6        \u001b[39m | \u001b[39m0.7222   \u001b[39m | \u001b[39m6.73     \u001b[39m | \u001b[39m0.005309 \u001b[39m |\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\nSTOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n\nIncrease the number of iterations (max_iter) or scale the data as shown in:\n    https://scikit-learn.org/stable/modules/preprocessing.html\nPlease also refer to the documentation for alternative solver options:\n    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n  n_iter_i = _check_optimize_result(\n","output_type":"stream"},{"name":"stdout","text":"| \u001b[39m7        \u001b[39m | \u001b[39m0.7242   \u001b[39m | \u001b[39m8.028    \u001b[39m | \u001b[39m0.002954 \u001b[39m |\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\nSTOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n\nIncrease the number of iterations (max_iter) or scale the data as shown in:\n    https://scikit-learn.org/stable/modules/preprocessing.html\nPlease also refer to the documentation for alternative solver options:\n    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n  n_iter_i = _check_optimize_result(\n","output_type":"stream"},{"name":"stdout","text":"| \u001b[39m8        \u001b[39m | \u001b[39m0.7237   \u001b[39m | \u001b[39m9.326    \u001b[39m | \u001b[39m0.009213 \u001b[39m |\n| \u001b[39m9        \u001b[39m | \u001b[39m0.7212   \u001b[39m | \u001b[39m2.549    \u001b[39m | \u001b[39m0.006473 \u001b[39m |\n| \u001b[39m10       \u001b[39m | \u001b[39m0.7222   \u001b[39m | \u001b[39m4.903    \u001b[39m | \u001b[39m5.436e-06\u001b[39m |\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\nSTOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n\nIncrease the number of iterations (max_iter) or scale the data as shown in:\n    https://scikit-learn.org/stable/modules/preprocessing.html\nPlease also refer to the documentation for alternative solver options:\n    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n  n_iter_i = _check_optimize_result(\n","output_type":"stream"},{"name":"stdout","text":"| \u001b[39m11       \u001b[39m | \u001b[39m0.7242   \u001b[39m | \u001b[39m9.998    \u001b[39m | \u001b[39m0.007703 \u001b[39m |\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\nSTOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n\nIncrease the number of iterations (max_iter) or scale the data as shown in:\n    https://scikit-learn.org/stable/modules/preprocessing.html\nPlease also refer to the documentation for alternative solver options:\n    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n  n_iter_i = _check_optimize_result(\n","output_type":"stream"},{"name":"stdout","text":"| \u001b[39m12       \u001b[39m | \u001b[39m0.7242   \u001b[39m | \u001b[39m8.657    \u001b[39m | \u001b[39m0.001159 \u001b[39m |\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\nSTOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n\nIncrease the number of iterations (max_iter) or scale the data as shown in:\n    https://scikit-learn.org/stable/modules/preprocessing.html\nPlease also refer to the documentation for alternative solver options:\n    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n  n_iter_i = _check_optimize_result(\n","output_type":"stream"},{"name":"stdout","text":"| \u001b[39m13       \u001b[39m | \u001b[39m0.7242   \u001b[39m | \u001b[39m7.662    \u001b[39m | \u001b[39m0.009762 \u001b[39m |\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\nSTOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n\nIncrease the number of iterations (max_iter) or scale the data as shown in:\n    https://scikit-learn.org/stable/modules/preprocessing.html\nPlease also refer to the documentation for alternative solver options:\n    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n  n_iter_i = _check_optimize_result(\n","output_type":"stream"},{"name":"stdout","text":"| \u001b[39m14       \u001b[39m | \u001b[39m0.7237   \u001b[39m | \u001b[39m9.723    \u001b[39m | \u001b[39m0.000938 \u001b[39m |\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\nSTOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n\nIncrease the number of iterations (max_iter) or scale the data as shown in:\n    https://scikit-learn.org/stable/modules/preprocessing.html\nPlease also refer to the documentation for alternative solver options:\n    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n  n_iter_i = _check_optimize_result(\n","output_type":"stream"},{"name":"stdout","text":"| \u001b[39m15       \u001b[39m | \u001b[39m0.7242   \u001b[39m | \u001b[39m8.361    \u001b[39m | \u001b[39m0.009054 \u001b[39m |\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\nSTOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n\nIncrease the number of iterations (max_iter) or scale the data as shown in:\n    https://scikit-learn.org/stable/modules/preprocessing.html\nPlease also refer to the documentation for alternative solver options:\n    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n  n_iter_i = _check_optimize_result(\n","output_type":"stream"},{"name":"stdout","text":"| \u001b[39m16       \u001b[39m | \u001b[39m0.7242   \u001b[39m | \u001b[39m8.948    \u001b[39m | \u001b[39m0.008835 \u001b[39m |\n| \u001b[39m17       \u001b[39m | \u001b[39m0.7212   \u001b[39m | \u001b[39m5.456    \u001b[39m | \u001b[39m0.009409 \u001b[39m |\n| \u001b[39m18       \u001b[39m | \u001b[39m0.7222   \u001b[39m | \u001b[39m4.339    \u001b[39m | \u001b[39m0.009892 \u001b[39m |\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\nSTOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n\nIncrease the number of iterations (max_iter) or scale the data as shown in:\n    https://scikit-learn.org/stable/modules/preprocessing.html\nPlease also refer to the documentation for alternative solver options:\n    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n  n_iter_i = _check_optimize_result(\n","output_type":"stream"},{"name":"stdout","text":"| \u001b[39m19       \u001b[39m | \u001b[39m0.7242   \u001b[39m | \u001b[39m7.474    \u001b[39m | \u001b[39m0.001603 \u001b[39m |\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\nSTOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n\nIncrease the number of iterations (max_iter) or scale the data as shown in:\n    https://scikit-learn.org/stable/modules/preprocessing.html\nPlease also refer to the documentation for alternative solver options:\n    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n  n_iter_i = _check_optimize_result(\n","output_type":"stream"},{"name":"stdout","text":"| \u001b[39m20       \u001b[39m | \u001b[39m0.7242   \u001b[39m | \u001b[39m7.853    \u001b[39m | \u001b[39m0.0003054\u001b[39m |\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\nSTOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n\nIncrease the number of iterations (max_iter) or scale the data as shown in:\n    https://scikit-learn.org/stable/modules/preprocessing.html\nPlease also refer to the documentation for alternative solver options:\n    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n  n_iter_i = _check_optimize_result(\n","output_type":"stream"},{"name":"stdout","text":"| \u001b[39m21       \u001b[39m | \u001b[39m0.7242   \u001b[39m | \u001b[39m8.796    \u001b[39m | \u001b[39m0.009751 \u001b[39m |\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\nSTOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n\nIncrease the number of iterations (max_iter) or scale the data as shown in:\n    https://scikit-learn.org/stable/modules/preprocessing.html\nPlease also refer to the documentation for alternative solver options:\n    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n  n_iter_i = _check_optimize_result(\n","output_type":"stream"},{"name":"stdout","text":"| \u001b[39m22       \u001b[39m | \u001b[39m0.7237   \u001b[39m | \u001b[39m8.208    \u001b[39m | \u001b[39m5.808e-05\u001b[39m |\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\nSTOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n\nIncrease the number of iterations (max_iter) or scale the data as shown in:\n    https://scikit-learn.org/stable/modules/preprocessing.html\nPlease also refer to the documentation for alternative solver options:\n    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n  n_iter_i = _check_optimize_result(\n","output_type":"stream"},{"name":"stdout","text":"| \u001b[35m23       \u001b[39m | \u001b[35m0.7247   \u001b[39m | \u001b[35m8.192    \u001b[39m | \u001b[35m0.006808 \u001b[39m |\n| \u001b[39m24       \u001b[39m | \u001b[39m0.7222   \u001b[39m | \u001b[39m5.021    \u001b[39m | \u001b[39m0.00672  \u001b[39m |\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\nSTOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n\nIncrease the number of iterations (max_iter) or scale the data as shown in:\n    https://scikit-learn.org/stable/modules/preprocessing.html\nPlease also refer to the documentation for alternative solver options:\n    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n  n_iter_i = _check_optimize_result(\n","output_type":"stream"},{"name":"stdout","text":"| \u001b[39m25       \u001b[39m | \u001b[39m0.7247   \u001b[39m | \u001b[39m8.117    \u001b[39m | \u001b[39m0.009309 \u001b[39m |\n=================================================\nHyperparameters tuning time: 35.510 seconds\nMeilleurs hyperparamètres : {'target': 0.7247247247247247, 'params': {'C': 8.191959671069789, 'tol': 0.006808099046926378}}\nTraining time: 1.411 seconds\nTest (prediction) time: 0.001 seconds\nRapport de classification :\n               precision    recall  f1-score   support\n\n       blues       0.67      0.72      0.70       200\n   classical       0.91      0.95      0.93       199\n     country       0.63      0.59      0.61       199\n       disco       0.66      0.67      0.66       200\n      hiphop       0.76      0.61      0.68       200\n        jazz       0.80      0.85      0.83       200\n       metal       0.82      0.86      0.84       200\n         pop       0.79      0.77      0.78       200\n      reggae       0.66      0.69      0.67       200\n        rock       0.54      0.54      0.54       200\n\n    accuracy                           0.72      1998\n   macro avg       0.72      0.72      0.72      1998\nweighted avg       0.72      0.72      0.72      1998\n\nMatrice de confusion :\n [[144   0  11   2   2  12  11   0   9   9]\n [  2 190   0   1   0   5   0   0   0   1]\n [ 17   1 117   8   2  14   3   7   5  25]\n [  2   4   5 134   5   0  10   6  10  24]\n [  8   1   3  15 123   0   6  12  31   1]\n [ 12   8   5   1   0 170   0   1   0   3]\n [  3   0   3   3   5   0 172   0   3  11]\n [  0   3   8  13   7   1   0 153   7   8]\n [  8   1   9   3  13   2   4  12 138  10]\n [ 18   1  24  24   4   8   5   2   7 107]]\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\nSTOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n\nIncrease the number of iterations (max_iter) or scale the data as shown in:\n    https://scikit-learn.org/stable/modules/preprocessing.html\nPlease also refer to the documentation for alternative solver options:\n    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n  n_iter_i = _check_optimize_result(\n","output_type":"stream"}],"execution_count":26},{"cell_type":"code","source":"import pandas as pd\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import LabelEncoder, StandardScaler\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.metrics import classification_report, confusion_matrix, roc_auc_score, RocCurveDisplay\nfrom bayes_opt import BayesianOptimization\nimport numpy as np\nimport matplotlib.pyplot as plt\n\n# Prétraitement des données\nX = df.drop(columns=['label'])  # Supprimez les colonnes non pertinentes\ny = df['label']\n\n# Encoder la variable cible\nencoder = LabelEncoder()\ny = encoder.fit_transform(y)\n\n# Normaliser les données\nscaler = StandardScaler()\nX_scaled = scaler.fit_transform(X)\n\n# Diviser les données en ensembles d'entraînement et de test\nX_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.2, random_state=42, stratify=y)\n\n# Fonction d'évaluation pour BayesianOptimization\ndef optimize_knn(n_neighbors, p):\n    model = KNeighborsClassifier(\n        n_neighbors=int(n_neighbors),  # Convertir en entier\n        p=int(p),                      # Distance : 1 pour Manhattan, 2 pour Euclidean\n        metric='minkowski'\n    )\n    model.fit(X_train, y_train)\n    return model.score(X_test, y_test)\n\n# Définir les limites des hyperparamètres\nparam_bounds = {\n    'n_neighbors': (1, 50),  # Nombre de voisins\n    'p': (1, 2)             # Distance : 1 (Manhattan) ou 2 (Euclidean)\n}\n\n# Lancer l'optimisation\noptimizer = BayesianOptimization(f=optimize_knn, pbounds=param_bounds, random_state=42)\nstart_opt = time.time_ns()\noptimizer.maximize(init_points=5, n_iter=20)\nend_opt = time.time_ns()\nopt_time = (end_opt - start_opt) / 1e9  # Convert nanoseconds to seconds\n\nprint(f\"Hyperparameters tuning time: {opt_time:.3f} seconds\")\n\n# Extraire les meilleurs hyperparamètres\nbest_params = optimizer.max\nprint(\"Meilleurs hyperparamètres :\", best_params)\n\n# Entraîner le modèle avec les meilleurs hyperparamètres\nbest_model_kmeans = KNeighborsClassifier(\n    n_neighbors=int(best_params['params']['n_neighbors']),\n    p=int(best_params['params']['p']),\n    metric='minkowski'\n)\nstart_train = time.time_ns()\nbest_model_kmeans.fit(X_train, y_train)\nend_train = time.time_ns()\ntrain_time = (end_train - start_train) / 1e9  # Convert nanoseconds to seconds\nprint(f\"Training time: {train_time:.3f} seconds\")\n\n# Évaluation du modèle\nstart_test = time.time_ns()\ny_pred = best_model_kmeans.predict(X_test)\nend_test = time.time_ns()\ntest_time = (end_test - start_test) / 1e9  # Convert nanoseconds to seconds\nprint(f\"Test (prediction) time: {test_time:.3f} seconds\")\nprint(\"Rapport de classification :\\n\", classification_report(y_test, y_pred, target_names=encoder.classes_))\n\n# Matrice de confusion\nconf_matrix = confusion_matrix(y_test, y_pred)\nprint(\"Matrice de confusion :\\n\", conf_matrix)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-16T03:05:24.405584Z","iopub.execute_input":"2025-02-16T03:05:24.405994Z","iopub.status.idle":"2025-02-16T03:05:45.350595Z","shell.execute_reply.started":"2025-02-16T03:05:24.405955Z","shell.execute_reply":"2025-02-16T03:05:45.349293Z"}},"outputs":[{"name":"stdout","text":"|   iter    |  target   | n_neig... |     p     |\n-------------------------------------------------\n| \u001b[39m1        \u001b[39m | \u001b[39m0.8293   \u001b[39m | \u001b[39m19.35    \u001b[39m | \u001b[39m1.951    \u001b[39m |\n| \u001b[39m2        \u001b[39m | \u001b[39m0.7808   \u001b[39m | \u001b[39m36.87    \u001b[39m | \u001b[39m1.599    \u001b[39m |\n| \u001b[35m3        \u001b[39m | \u001b[35m0.8859   \u001b[39m | \u001b[35m8.645    \u001b[39m | \u001b[35m1.156    \u001b[39m |\n| \u001b[35m4        \u001b[39m | \u001b[35m0.9164   \u001b[39m | \u001b[35m3.846    \u001b[39m | \u001b[35m1.866    \u001b[39m |\n| \u001b[39m5        \u001b[39m | \u001b[39m0.7923   \u001b[39m | \u001b[39m30.45    \u001b[39m | \u001b[39m1.708    \u001b[39m |\n| \u001b[35m6        \u001b[39m | \u001b[35m0.9214   \u001b[39m | \u001b[35m1.012    \u001b[39m | \u001b[35m1.127    \u001b[39m |\n| \u001b[39m7        \u001b[39m | \u001b[39m0.9214   \u001b[39m | \u001b[39m1.11     \u001b[39m | \u001b[39m1.997    \u001b[39m |\n| \u001b[39m8        \u001b[39m | \u001b[39m0.9214   \u001b[39m | \u001b[39m1.938    \u001b[39m | \u001b[39m1.021    \u001b[39m |\n| \u001b[39m9        \u001b[39m | \u001b[39m0.9214   \u001b[39m | \u001b[39m1.673    \u001b[39m | \u001b[39m1.599    \u001b[39m |\n| \u001b[39m10       \u001b[39m | \u001b[39m0.9214   \u001b[39m | \u001b[39m1.546    \u001b[39m | \u001b[39m1.017    \u001b[39m |\n| \u001b[39m11       \u001b[39m | \u001b[39m0.9214   \u001b[39m | \u001b[39m1.028    \u001b[39m | \u001b[39m1.549    \u001b[39m |\n| \u001b[39m12       \u001b[39m | \u001b[39m0.9214   \u001b[39m | \u001b[39m1.412    \u001b[39m | \u001b[39m1.437    \u001b[39m |\n| \u001b[39m13       \u001b[39m | \u001b[39m0.9214   \u001b[39m | \u001b[39m1.442    \u001b[39m | \u001b[39m1.059    \u001b[39m |\n| \u001b[39m14       \u001b[39m | \u001b[39m0.9214   \u001b[39m | \u001b[39m1.54     \u001b[39m | \u001b[39m1.98     \u001b[39m |\n| \u001b[39m15       \u001b[39m | \u001b[39m0.9214   \u001b[39m | \u001b[39m1.445    \u001b[39m | \u001b[39m1.007    \u001b[39m |\n| \u001b[39m16       \u001b[39m | \u001b[39m0.9214   \u001b[39m | \u001b[39m1.014    \u001b[39m | \u001b[39m1.947    \u001b[39m |\n| \u001b[39m17       \u001b[39m | \u001b[39m0.9214   \u001b[39m | \u001b[39m1.392    \u001b[39m | \u001b[39m1.549    \u001b[39m |\n| \u001b[39m18       \u001b[39m | \u001b[39m0.9214   \u001b[39m | \u001b[39m1.001    \u001b[39m | \u001b[39m1.014    \u001b[39m |\n| \u001b[39m19       \u001b[39m | \u001b[39m0.9214   \u001b[39m | \u001b[39m1.014    \u001b[39m | \u001b[39m1.981    \u001b[39m |\n| \u001b[39m20       \u001b[39m | \u001b[39m0.9214   \u001b[39m | \u001b[39m1.256    \u001b[39m | \u001b[39m1.999    \u001b[39m |\n| \u001b[39m21       \u001b[39m | \u001b[39m0.9214   \u001b[39m | \u001b[39m1.552    \u001b[39m | \u001b[39m1.004    \u001b[39m |\n| \u001b[39m22       \u001b[39m | \u001b[39m0.7673   \u001b[39m | \u001b[39m50.0     \u001b[39m | \u001b[39m1.543    \u001b[39m |\n| \u001b[39m23       \u001b[39m | \u001b[39m0.9214   \u001b[39m | \u001b[39m1.401    \u001b[39m | \u001b[39m1.498    \u001b[39m |\n| \u001b[39m24       \u001b[39m | \u001b[39m0.9214   \u001b[39m | \u001b[39m1.382    \u001b[39m | \u001b[39m1.002    \u001b[39m |\n| \u001b[39m25       \u001b[39m | \u001b[39m0.9214   \u001b[39m | \u001b[39m1.458    \u001b[39m | \u001b[39m1.961    \u001b[39m |\n=================================================\nHyperparameters tuning time: 20.222 seconds\nMeilleurs hyperparamètres : {'target': 0.9214214214214215, 'params': {'n_neighbors': 1.0119037872911238, 'p': 1.1269360576741763}}\nTraining time: 0.003 seconds\nTest (prediction) time: 0.665 seconds\nRapport de classification :\n               precision    recall  f1-score   support\n\n       blues       0.91      0.93      0.92       200\n   classical       0.94      0.96      0.95       199\n     country       0.87      0.81      0.84       199\n       disco       0.90      0.94      0.92       200\n      hiphop       0.94      0.95      0.95       200\n        jazz       0.91      0.90      0.90       200\n       metal       0.97      0.98      0.98       200\n         pop       0.96      0.90      0.93       200\n      reggae       0.90      0.94      0.92       200\n        rock       0.90      0.90      0.90       200\n\n    accuracy                           0.92      1998\n   macro avg       0.92      0.92      0.92      1998\nweighted avg       0.92      0.92      0.92      1998\n\nMatrice de confusion :\n [[186   1   3   1   0   3   0   0   5   1]\n [  1 191   1   0   1   3   0   1   0   1]\n [  7   1 161   5   2   6   0   3   6   8]\n [  0   0   2 189   0   2   2   1   1   3]\n [  0   1   1   2 190   0   1   2   2   1]\n [  5   8   4   0   2 180   0   0   0   1]\n [  1   0   0   0   1   0 196   0   1   1]\n [  0   0   3   6   4   1   0 179   4   3]\n [  2   1   5   0   2   1   0   0 189   0]\n [  2   1   5   6   0   2   3   0   1 180]]\n","output_type":"stream"}],"execution_count":27},{"cell_type":"code","source":"# Import necessary libraries\nimport pandas as pd\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import LabelEncoder, StandardScaler\nfrom sklearn.svm import SVC\nfrom sklearn.metrics import classification_report, confusion_matrix, roc_auc_score, RocCurveDisplay\nfrom bayes_opt import BayesianOptimization\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom sklearn.ensemble import RandomForestClassifier\n\n\n# Prétraitement des données\nX = df.drop(columns=['label'])  # Supprimez les colonnes non pertinentes\ny = df['label']\n\n# Encoder la variable cible\nencoder = LabelEncoder()\ny = encoder.fit_transform(y)\n\n# No need to Normaliser les données\n# scaler = StandardScaler()\n# X_scaled = scaler.fit_transform(X)\n\n# Diviser les données en ensembles d'entraînement et de test\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42, stratify=y)\n# Function for Bayesian Optimization with Random Forest\ndef optimize_rf(n_estimators, max_depth):\n    # Convert float parameters to integers as RandomForest expects integers\n    n_estimators = int(n_estimators)\n    max_depth = int(max_depth)\n    \n    model = RandomForestClassifier(\n        n_estimators=n_estimators, \n        max_depth=max_depth, \n        random_state=42,\n        n_jobs=-1\n    )\n    model.fit(X_train, y_train)\n    return model.score(X_test, y_test)\n\n# Define parameter bounds for Random Forest\nparam_bounds_rf = {\n    'n_estimators': (10, 200),  # Number of trees\n    'max_depth': (5, 50)       # Maximum depth of the trees\n}\n\n# Run Bayesian Optimization\noptimizer_rf = BayesianOptimization(f=optimize_rf, pbounds=param_bounds_rf, random_state=42)\nstart_opt = time.time_ns()\noptimizer_rf.maximize(init_points=5, n_iter=50)\nend_opt = time.time_ns()\nopt_time = (end_opt - start_opt) / 1e9  # Convert nanoseconds to seconds\n\nprint(f\"Hyperparameters tuning time: {opt_time:.3f} seconds\")\n\n# Extract the best parameters\nbest_params_rf = optimizer_rf.max\nprint(\"Meilleurs hyperparamètres :\", best_params_rf)\n\n# Train the model with the best hyperparameters\nbest_model_rf = RandomForestClassifier(\n    n_estimators=50,\n    max_depth=25,\n    random_state=42,\n    n_jobs=-1\n)\nstart_train = time.time_ns()\nbest_model_rf.fit(X_train, y_train) \nend_train = time.time_ns()\ntrain_time = (end_train - start_train) / 1e9  # Convert nanoseconds to seconds\nprint(f\"Training time: {train_time:.3f} seconds\")\n\n# Model evaluation\nstart_test = time.time_ns()\ny_pred_rf = best_model_rf.predict(X_test)\nend_test = time.time_ns()\ntest_time = (end_test - start_test) / 1e9  # Convert nanoseconds to seconds\nprint(f\"Test (prediction) time: {test_time:.3f} seconds\")\nprint(\"Rapport de classification :\\n\", classification_report(y_test, y_pred_rf, target_names=encoder.classes_))\n\n# Confusion matrix\nconf_matrix_rf = confusion_matrix(y_test, y_pred_rf)\nprint(\"Matrice de confusion :\\n\", conf_matrix_rf)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-16T03:05:45.351850Z","iopub.execute_input":"2025-02-16T03:05:45.352232Z","iopub.status.idle":"2025-02-16T03:08:06.710275Z","shell.execute_reply.started":"2025-02-16T03:05:45.352196Z","shell.execute_reply":"2025-02-16T03:08:06.709369Z"}},"outputs":[{"name":"stdout","text":"|   iter    |  target   | max_depth | n_esti... |\n-------------------------------------------------\n| \u001b[39m1        \u001b[39m | \u001b[39m0.8575   \u001b[39m | \u001b[39m21.85    \u001b[39m | \u001b[39m190.6    \u001b[39m |\n| \u001b[35m2        \u001b[39m | \u001b[35m0.8582   \u001b[39m | \u001b[35m37.94    \u001b[39m | \u001b[35m123.7    \u001b[39m |\n| \u001b[39m3        \u001b[39m | \u001b[39m0.8055   \u001b[39m | \u001b[39m12.02    \u001b[39m | \u001b[39m39.64    \u001b[39m |\n| \u001b[39m4        \u001b[39m | \u001b[39m0.6984   \u001b[39m | \u001b[39m7.614    \u001b[39m | \u001b[39m174.6    \u001b[39m |\n| \u001b[39m5        \u001b[39m | \u001b[39m0.8569   \u001b[39m | \u001b[39m32.05    \u001b[39m | \u001b[39m144.5    \u001b[39m |\n| \u001b[35m6        \u001b[39m | \u001b[35m0.8595   \u001b[39m | \u001b[35m39.0     \u001b[39m | \u001b[35m125.0    \u001b[39m |\n| \u001b[35m7        \u001b[39m | \u001b[35m0.8602   \u001b[39m | \u001b[35m37.64    \u001b[39m | \u001b[35m199.3    \u001b[39m |\n| \u001b[39m8        \u001b[39m | \u001b[39m0.8582   \u001b[39m | \u001b[39m46.59    \u001b[39m | \u001b[39m178.3    \u001b[39m |\n| \u001b[39m9        \u001b[39m | \u001b[39m0.8602   \u001b[39m | \u001b[39m49.87    \u001b[39m | \u001b[39m153.1    \u001b[39m |\n| \u001b[39m10       \u001b[39m | \u001b[39m0.8535   \u001b[39m | \u001b[39m49.94    \u001b[39m | \u001b[39m94.71    \u001b[39m |\n| \u001b[39m11       \u001b[39m | \u001b[39m0.8482   \u001b[39m | \u001b[39m21.26    \u001b[39m | \u001b[39m92.68    \u001b[39m |\n| \u001b[39m12       \u001b[39m | \u001b[39m0.8478   \u001b[39m | \u001b[39m49.67    \u001b[39m | \u001b[39m68.0     \u001b[39m |\n| \u001b[39m13       \u001b[39m | \u001b[39m0.5986   \u001b[39m | \u001b[39m5.725    \u001b[39m | \u001b[39m118.3    \u001b[39m |\n| \u001b[39m14       \u001b[39m | \u001b[39m0.8582   \u001b[39m | \u001b[39m23.33    \u001b[39m | \u001b[39m69.89    \u001b[39m |\n| \u001b[39m15       \u001b[39m | \u001b[39m0.7484   \u001b[39m | \u001b[39m49.46    \u001b[39m | \u001b[39m10.93    \u001b[39m |\n| \u001b[39m16       \u001b[39m | \u001b[39m0.5609   \u001b[39m | \u001b[39m5.479    \u001b[39m | \u001b[39m10.83    \u001b[39m |\n| \u001b[39m17       \u001b[39m | \u001b[39m0.5953   \u001b[39m | \u001b[39m5.074    \u001b[39m | \u001b[39m64.75    \u001b[39m |\n| \u001b[39m18       \u001b[39m | \u001b[39m0.8482   \u001b[39m | \u001b[39m35.61    \u001b[39m | \u001b[39m80.46    \u001b[39m |\n| \u001b[39m19       \u001b[39m | \u001b[39m0.8392   \u001b[39m | \u001b[39m36.19    \u001b[39m | \u001b[39m51.29    \u001b[39m |\n| \u001b[39m20       \u001b[39m | \u001b[39m0.8589   \u001b[39m | \u001b[39m49.89    \u001b[39m | \u001b[39m112.3    \u001b[39m |\n| \u001b[39m21       \u001b[39m | \u001b[39m0.8592   \u001b[39m | \u001b[39m34.0     \u001b[39m | \u001b[39m165.0    \u001b[39m |\n| \u001b[39m22       \u001b[39m | \u001b[39m0.6563   \u001b[39m | \u001b[39m6.653    \u001b[39m | \u001b[39m199.8    \u001b[39m |\n| \u001b[39m23       \u001b[39m | \u001b[39m0.8579   \u001b[39m | \u001b[39m32.63    \u001b[39m | \u001b[39m183.9    \u001b[39m |\n| \u001b[39m24       \u001b[39m | \u001b[39m0.8355   \u001b[39m | \u001b[39m49.88    \u001b[39m | \u001b[39m39.81    \u001b[39m |\n| \u001b[39m25       \u001b[39m | \u001b[39m0.8539   \u001b[39m | \u001b[39m35.98    \u001b[39m | \u001b[39m101.9    \u001b[39m |\n| \u001b[39m26       \u001b[39m | \u001b[39m0.8602   \u001b[39m | \u001b[39m49.98    \u001b[39m | \u001b[39m199.3    \u001b[39m |\n| \u001b[39m27       \u001b[39m | \u001b[39m0.8595   \u001b[39m | \u001b[39m49.2     \u001b[39m | \u001b[39m138.5    \u001b[39m |\n| \u001b[39m28       \u001b[39m | \u001b[39m0.8278   \u001b[39m | \u001b[39m30.66    \u001b[39m | \u001b[39m33.76    \u001b[39m |\n| \u001b[39m29       \u001b[39m | \u001b[39m0.8478   \u001b[39m | \u001b[39m34.1     \u001b[39m | \u001b[39m66.08    \u001b[39m |\n| \u001b[39m30       \u001b[39m | \u001b[39m0.8599   \u001b[39m | \u001b[39m49.91    \u001b[39m | \u001b[39m167.7    \u001b[39m |\n| \u001b[39m31       \u001b[39m | \u001b[39m0.8412   \u001b[39m | \u001b[39m49.92    \u001b[39m | \u001b[39m54.37    \u001b[39m |\n| \u001b[39m32       \u001b[39m | \u001b[39m0.8602   \u001b[39m | \u001b[39m39.32    \u001b[39m | \u001b[39m153.5    \u001b[39m |\n| \u001b[39m33       \u001b[39m | \u001b[39m0.8579   \u001b[39m | \u001b[39m20.05    \u001b[39m | \u001b[39m153.3    \u001b[39m |\n| \u001b[39m34       \u001b[39m | \u001b[39m0.8512   \u001b[39m | \u001b[39m24.07    \u001b[39m | \u001b[39m81.31    \u001b[39m |\n| \u001b[39m35       \u001b[39m | \u001b[39m0.8582   \u001b[39m | \u001b[39m49.66    \u001b[39m | \u001b[39m188.8    \u001b[39m |\n| \u001b[39m36       \u001b[39m | \u001b[39m0.8595   \u001b[39m | \u001b[39m49.9     \u001b[39m | \u001b[39m126.6    \u001b[39m |\n| \u001b[39m37       \u001b[39m | \u001b[39m0.8465   \u001b[39m | \u001b[39m23.98    \u001b[39m | \u001b[39m47.95    \u001b[39m |\n| \u001b[39m38       \u001b[39m | \u001b[39m0.8602   \u001b[39m | \u001b[39m28.02    \u001b[39m | \u001b[39m199.7    \u001b[39m |\n| \u001b[39m39       \u001b[39m | \u001b[39m0.8478   \u001b[39m | \u001b[39m49.93    \u001b[39m | \u001b[39m83.84    \u001b[39m |\n| \u001b[39m40       \u001b[39m | \u001b[39m0.8602   \u001b[39m | \u001b[39m27.94    \u001b[39m | \u001b[39m157.0    \u001b[39m |\n| \u001b[39m41       \u001b[39m | \u001b[39m0.8519   \u001b[39m | \u001b[39m30.95    \u001b[39m | \u001b[39m92.21    \u001b[39m |\n| \u001b[39m42       \u001b[39m | \u001b[39m0.8592   \u001b[39m | \u001b[39m29.96    \u001b[39m | \u001b[39m192.2    \u001b[39m |\n| \u001b[35m43       \u001b[39m | \u001b[35m0.8605   \u001b[39m | \u001b[35m25.87    \u001b[39m | \u001b[35m174.5    \u001b[39m |\n| \u001b[39m44       \u001b[39m | \u001b[39m0.8595   \u001b[39m | \u001b[39m41.18    \u001b[39m | \u001b[39m113.5    \u001b[39m |\n| \u001b[39m45       \u001b[39m | \u001b[39m0.8575   \u001b[39m | \u001b[39m20.99    \u001b[39m | \u001b[39m142.3    \u001b[39m |\n| \u001b[39m46       \u001b[39m | \u001b[39m0.6059   \u001b[39m | \u001b[39m5.951    \u001b[39m | \u001b[39m147.2    \u001b[39m |\n| \u001b[39m47       \u001b[39m | \u001b[39m0.8575   \u001b[39m | \u001b[39m29.19    \u001b[39m | \u001b[39m133.0    \u001b[39m |\n| \u001b[39m48       \u001b[39m | \u001b[39m0.8565   \u001b[39m | \u001b[39m26.91    \u001b[39m | \u001b[39m106.4    \u001b[39m |\n| \u001b[39m49       \u001b[39m | \u001b[39m0.8589   \u001b[39m | \u001b[39m25.29    \u001b[39m | \u001b[39m148.8    \u001b[39m |\n| \u001b[39m50       \u001b[39m | \u001b[39m0.8582   \u001b[39m | \u001b[39m40.38    \u001b[39m | \u001b[39m137.0    \u001b[39m |\n| \u001b[39m51       \u001b[39m | \u001b[39m0.8572   \u001b[39m | \u001b[39m22.91    \u001b[39m | \u001b[39m163.8    \u001b[39m |\n| \u001b[39m52       \u001b[39m | \u001b[39m0.8605   \u001b[39m | \u001b[39m38.06    \u001b[39m | \u001b[39m173.5    \u001b[39m |\n| \u001b[39m53       \u001b[39m | \u001b[39m0.8498   \u001b[39m | \u001b[39m28.63    \u001b[39m | \u001b[39m73.55    \u001b[39m |\n| \u001b[39m54       \u001b[39m | \u001b[39m0.8458   \u001b[39m | \u001b[39m25.85    \u001b[39m | \u001b[39m60.24    \u001b[39m |\n| \u001b[39m55       \u001b[39m | \u001b[39m0.8572   \u001b[39m | \u001b[39m43.94    \u001b[39m | \u001b[39m161.5    \u001b[39m |\n=================================================\nHyperparameters tuning time: 140.279 seconds\nMeilleurs hyperparamètres : {'target': 0.8605271938605272, 'params': {'max_depth': 25.86642987254168, 'n_estimators': 174.52985722872756}}\nTraining time: 0.999 seconds\nTest (prediction) time: 0.038 seconds\nRapport de classification :\n               precision    recall  f1-score   support\n\n       blues       0.81      0.85      0.83       300\n   classical       0.89      0.96      0.93       299\n     country       0.76      0.76      0.76       299\n       disco       0.82      0.85      0.83       300\n      hiphop       0.90      0.82      0.86       299\n        jazz       0.85      0.88      0.86       300\n       metal       0.85      0.92      0.89       300\n         pop       0.91      0.83      0.86       300\n      reggae       0.79      0.83      0.81       300\n        rock       0.86      0.71      0.78       300\n\n    accuracy                           0.84      2997\n   macro avg       0.84      0.84      0.84      2997\nweighted avg       0.84      0.84      0.84      2997\n\nMatrice de confusion :\n [[255   2   6   7   0   7  14   0   9   0]\n [  0 288   5   0   0   5   0   0   0   1]\n [ 26   3 228   3   0  14   0   6  12   7]\n [  2   1   6 254   6   1   7   2   8  13]\n [  2   2   4   7 246   2   5  12  18   1]\n [  6  19   5   2   0 265   1   1   0   1]\n [  3   1   0   5   4   1 277   0   5   4]\n [  0   1  11  14   8   3   0 248  10   5]\n [  9   3  11   6   9   2   2   5 250   3]\n [ 12   3  24  12   0  13  19   0   4 213]]\n","output_type":"stream"}],"execution_count":28},{"cell_type":"code","source":"# Import necessary libraries\nimport pandas as pd\nimport time\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.metrics import classification_report, confusion_matrix\nfrom bayes_opt import BayesianOptimization\nfrom xgboost import XGBClassifier\n\nX = df.drop(columns=['label'])  # Supprime la colonne cible\ny = df['label']\n\n# Encoder la variable cible\nencoder = LabelEncoder()\ny = encoder.fit_transform(y)\n\n# Diviser les données en ensembles d'entraînement et de test\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42, stratify=y)\n\n# Function for Bayesian Optimization with XGBoost\ndef optimize_xgb(n_estimators, max_depth, learning_rate):\n    # Convert float parameters to integers where necessary\n    n_estimators = int(n_estimators)\n    max_depth = int(max_depth)\n\n    model = XGBClassifier(\n        n_estimators=n_estimators,\n        max_depth=max_depth,\n        learning_rate=learning_rate,\n        objective='multi:softmax',\n        eval_metric='mlogloss',\n        use_label_encoder=False,\n        random_state=42,\n        n_jobs=-1\n    )\n    model.fit(X_train, y_train)\n    return model.score(X_test, y_test)\n\n# Define parameter bounds for XGBoost\nparam_bounds_xgb = {\n    'n_estimators': (10, 200),\n    'max_depth': (3, 20),\n    'learning_rate': (0.01, 0.3)\n}\n\n# Run Bayesian Optimization\noptimizer_xgb = BayesianOptimization(f=optimize_xgb, pbounds=param_bounds_xgb, random_state=42)\nstart_opt = time.time_ns()\noptimizer_xgb.maximize(init_points=5, n_iter=50)\nend_opt = time.time_ns()\nopt_time = (end_opt - start_opt) / 1e9  # Convert nanoseconds to seconds\n\nprint(f\"Hyperparameters tuning time: {opt_time:.3f} seconds\")\n\n# Extract the best parameters\nbest_params_xgb = optimizer_xgb.max['params']\nbest_params_xgb['n_estimators'] = int(best_params_xgb['n_estimators'])\nbest_params_xgb['max_depth'] = int(best_params_xgb['max_depth'])\nprint(\"Meilleurs hyperparamètres :\", best_params_xgb)\n\n# Train the model with the best hyperparameters\nbest_model_xgb = XGBClassifier(\n    n_estimators=best_params_xgb['n_estimators'],\n    max_depth=best_params_xgb['max_depth'],\n    learning_rate=best_params_xgb['learning_rate'],\n    objective='multi:softmax',\n    eval_metric='mlogloss',\n    use_label_encoder=False,\n    random_state=42,\n    n_jobs=-1\n)\n\nstart_train = time.time_ns()\nbest_model_xgb.fit(X_train, y_train)\nend_train = time.time_ns()\ntrain_time = (end_train - start_train) / 1e9  # Convert nanoseconds to seconds\nprint(f\"Training time: {train_time:.3f} seconds\")\n\n# Model evaluation\nstart_test = time.time_ns()\ny_pred_xgb = best_model_xgb.predict(X_test)\nend_test = time.time_ns()\ntest_time = (end_test - start_test) / 1e9  # Convert nanoseconds to seconds\nprint(f\"Test (prediction) time: {test_time:.3f} seconds\")\n\n# Rapport de classification\nprint(\"Rapport de classification :\\n\", classification_report(y_test, y_pred_xgb, target_names=encoder.classes_))\n\n# Confusion matrix\nconf_matrix_xgb = confusion_matrix(y_test, y_pred_xgb)\nprint(\"Matrice de confusion :\\n\", conf_matrix_xgb)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-16T03:08:06.711526Z","iopub.execute_input":"2025-02-16T03:08:06.711805Z","iopub.status.idle":"2025-02-16T03:22:23.159694Z","shell.execute_reply.started":"2025-02-16T03:08:06.711780Z","shell.execute_reply":"2025-02-16T03:22:23.158670Z"}},"outputs":[{"name":"stdout","text":"|   iter    |  target   | learni... | max_depth | n_esti... |\n-------------------------------------------------------------\n| \u001b[39m1        \u001b[39m | \u001b[39m0.8802   \u001b[39m | \u001b[39m0.1186   \u001b[39m | \u001b[39m19.16    \u001b[39m | \u001b[39m149.1    \u001b[39m |\n| \u001b[39m2        \u001b[39m | \u001b[39m0.8272   \u001b[39m | \u001b[39m0.1836   \u001b[39m | \u001b[39m5.652    \u001b[39m | \u001b[39m39.64    \u001b[39m |\n| \u001b[39m3        \u001b[39m | \u001b[39m0.8392   \u001b[39m | \u001b[39m0.02684  \u001b[39m | \u001b[39m17.72    \u001b[39m | \u001b[39m124.2    \u001b[39m |\n| \u001b[39m4        \u001b[39m | \u001b[39m0.8685   \u001b[39m | \u001b[39m0.2153   \u001b[39m | \u001b[39m3.35     \u001b[39m | \u001b[39m194.3    \u001b[39m |\n| \u001b[39m5        \u001b[39m | \u001b[39m0.8629   \u001b[39m | \u001b[39m0.2514   \u001b[39m | \u001b[39m6.61     \u001b[39m | \u001b[39m44.55    \u001b[39m |\n| \u001b[39m6        \u001b[39m | \u001b[39m0.8699   \u001b[39m | \u001b[39m0.2369   \u001b[39m | \u001b[39m3.392    \u001b[39m | \u001b[39m194.2    \u001b[39m |\n| \u001b[39m7        \u001b[39m | \u001b[39m0.8629   \u001b[39m | \u001b[39m0.06187  \u001b[39m | \u001b[39m17.48    \u001b[39m | \u001b[39m150.5    \u001b[39m |\n| \u001b[35m8        \u001b[39m | \u001b[35m0.8805   \u001b[39m | \u001b[35m0.1463   \u001b[39m | \u001b[35m18.11    \u001b[39m | \u001b[35m147.2    \u001b[39m |\n| \u001b[35m9        \u001b[39m | \u001b[35m0.8932   \u001b[39m | \u001b[35m0.2571   \u001b[39m | \u001b[35m4.503    \u001b[39m | \u001b[35m191.0    \u001b[39m |\n| \u001b[39m10       \u001b[39m | \u001b[39m0.8916   \u001b[39m | \u001b[39m0.258    \u001b[39m | \u001b[39m8.046    \u001b[39m | \u001b[39m191.5    \u001b[39m |\n| \u001b[39m11       \u001b[39m | \u001b[39m0.8785   \u001b[39m | \u001b[39m0.08878  \u001b[39m | \u001b[39m6.733    \u001b[39m | \u001b[39m186.8    \u001b[39m |\n| \u001b[39m12       \u001b[39m | \u001b[39m0.8802   \u001b[39m | \u001b[39m0.09182  \u001b[39m | \u001b[39m13.39    \u001b[39m | \u001b[39m191.7    \u001b[39m |\n| \u001b[39m13       \u001b[39m | \u001b[39m0.8829   \u001b[39m | \u001b[39m0.2844   \u001b[39m | \u001b[39m10.82    \u001b[39m | \u001b[39m196.2    \u001b[39m |\n| \u001b[39m14       \u001b[39m | \u001b[39m0.8622   \u001b[39m | \u001b[39m0.05479  \u001b[39m | \u001b[39m19.9     \u001b[39m | \u001b[39m141.4    \u001b[39m |\n| \u001b[39m15       \u001b[39m | \u001b[39m0.8859   \u001b[39m | \u001b[39m0.266    \u001b[39m | \u001b[39m16.85    \u001b[39m | \u001b[39m198.1    \u001b[39m |\n| \u001b[39m16       \u001b[39m | \u001b[39m0.8829   \u001b[39m | \u001b[39m0.292    \u001b[39m | \u001b[39m19.76    \u001b[39m | \u001b[39m194.4    \u001b[39m |\n| \u001b[39m17       \u001b[39m | \u001b[39m0.8769   \u001b[39m | \u001b[39m0.1418   \u001b[39m | \u001b[39m19.68    \u001b[39m | \u001b[39m187.2    \u001b[39m |\n| \u001b[39m18       \u001b[39m | \u001b[39m0.8836   \u001b[39m | \u001b[39m0.2685   \u001b[39m | \u001b[39m13.92    \u001b[39m | \u001b[39m182.4    \u001b[39m |\n| \u001b[39m19       \u001b[39m | \u001b[39m0.8839   \u001b[39m | \u001b[39m0.2857   \u001b[39m | \u001b[39m18.12    \u001b[39m | \u001b[39m178.6    \u001b[39m |\n| \u001b[39m20       \u001b[39m | \u001b[39m0.8815   \u001b[39m | \u001b[39m0.2396   \u001b[39m | \u001b[39m12.92    \u001b[39m | \u001b[39m176.1    \u001b[39m |\n| \u001b[39m21       \u001b[39m | \u001b[39m0.8749   \u001b[39m | \u001b[39m0.08931  \u001b[39m | \u001b[39m18.49    \u001b[39m | \u001b[39m172.6    \u001b[39m |\n| \u001b[35m22       \u001b[39m | \u001b[35m0.8969   \u001b[39m | \u001b[35m0.2118   \u001b[39m | \u001b[35m7.439    \u001b[39m | \u001b[35m178.9    \u001b[39m |\n| \u001b[39m23       \u001b[39m | \u001b[39m0.8779   \u001b[39m | \u001b[39m0.1065   \u001b[39m | \u001b[39m5.63     \u001b[39m | \u001b[39m175.7    \u001b[39m |\n| \u001b[39m24       \u001b[39m | \u001b[39m0.8535   \u001b[39m | \u001b[39m0.03316  \u001b[39m | \u001b[39m9.975    \u001b[39m | \u001b[39m181.1    \u001b[39m |\n| \u001b[39m25       \u001b[39m | \u001b[39m0.8929   \u001b[39m | \u001b[39m0.1673   \u001b[39m | \u001b[39m5.108    \u001b[39m | \u001b[39m179.1    \u001b[39m |\n| \u001b[39m26       \u001b[39m | \u001b[39m0.8916   \u001b[39m | \u001b[39m0.1678   \u001b[39m | \u001b[39m7.279    \u001b[39m | \u001b[39m193.8    \u001b[39m |\n| \u001b[39m27       \u001b[39m | \u001b[39m0.8839   \u001b[39m | \u001b[39m0.2672   \u001b[39m | \u001b[39m17.43    \u001b[39m | \u001b[39m182.4    \u001b[39m |\n| \u001b[39m28       \u001b[39m | \u001b[39m0.8906   \u001b[39m | \u001b[39m0.2494   \u001b[39m | \u001b[39m8.878    \u001b[39m | \u001b[39m176.3    \u001b[39m |\n| \u001b[39m29       \u001b[39m | \u001b[39m0.8632   \u001b[39m | \u001b[39m0.1801   \u001b[39m | \u001b[39m3.171    \u001b[39m | \u001b[39m182.7    \u001b[39m |\n| \u001b[39m30       \u001b[39m | \u001b[39m0.8695   \u001b[39m | \u001b[39m0.04825  \u001b[39m | \u001b[39m13.36    \u001b[39m | \u001b[39m199.9    \u001b[39m |\n| \u001b[39m31       \u001b[39m | \u001b[39m0.8799   \u001b[39m | \u001b[39m0.1386   \u001b[39m | \u001b[39m19.92    \u001b[39m | \u001b[39m199.2    \u001b[39m |\n| \u001b[39m32       \u001b[39m | \u001b[39m0.8812   \u001b[39m | \u001b[39m0.1428   \u001b[39m | \u001b[39m14.61    \u001b[39m | \u001b[39m186.5    \u001b[39m |\n| \u001b[39m33       \u001b[39m | \u001b[39m0.8839   \u001b[39m | \u001b[39m0.244    \u001b[39m | \u001b[39m10.6     \u001b[39m | \u001b[39m172.2    \u001b[39m |\n| \u001b[39m34       \u001b[39m | \u001b[39m0.8292   \u001b[39m | \u001b[39m0.01207  \u001b[39m | \u001b[39m15.59    \u001b[39m | \u001b[39m195.0    \u001b[39m |\n| \u001b[35m35       \u001b[39m | \u001b[35m0.8982   \u001b[39m | \u001b[35m0.2223   \u001b[39m | \u001b[35m5.819    \u001b[39m | \u001b[35m192.0    \u001b[39m |\n| \u001b[39m36       \u001b[39m | \u001b[39m0.8275   \u001b[39m | \u001b[39m0.02527  \u001b[39m | \u001b[39m6.558    \u001b[39m | \u001b[39m189.7    \u001b[39m |\n| \u001b[39m37       \u001b[39m | \u001b[39m0.7341   \u001b[39m | \u001b[39m0.01512  \u001b[39m | \u001b[39m4.906    \u001b[39m | \u001b[39m192.5    \u001b[39m |\n| \u001b[39m38       \u001b[39m | \u001b[39m0.8131   \u001b[39m | \u001b[39m0.0493   \u001b[39m | \u001b[39m19.08    \u001b[39m | \u001b[39m29.1     \u001b[39m |\n| \u001b[39m39       \u001b[39m | \u001b[39m0.8849   \u001b[39m | \u001b[39m0.09314  \u001b[39m | \u001b[39m6.95     \u001b[39m | \u001b[39m178.8    \u001b[39m |\n| \u001b[39m40       \u001b[39m | \u001b[39m0.8829   \u001b[39m | \u001b[39m0.09035  \u001b[39m | \u001b[39m6.415    \u001b[39m | \u001b[39m191.7    \u001b[39m |\n| \u001b[35m41       \u001b[39m | \u001b[35m0.9019   \u001b[39m | \u001b[35m0.2522   \u001b[39m | \u001b[35m5.84     \u001b[39m | \u001b[35m191.4    \u001b[39m |\n| \u001b[39m42       \u001b[39m | \u001b[39m0.8652   \u001b[39m | \u001b[39m0.2324   \u001b[39m | \u001b[39m6.793    \u001b[39m | \u001b[39m48.96    \u001b[39m |\n| \u001b[39m43       \u001b[39m | \u001b[39m0.8829   \u001b[39m | \u001b[39m0.1516   \u001b[39m | \u001b[39m16.62    \u001b[39m | \u001b[39m176.4    \u001b[39m |\n| \u001b[39m44       \u001b[39m | \u001b[39m0.8408   \u001b[39m | \u001b[39m0.168    \u001b[39m | \u001b[39m9.569    \u001b[39m | \u001b[39m31.51    \u001b[39m |\n| \u001b[39m45       \u001b[39m | \u001b[39m0.8255   \u001b[39m | \u001b[39m0.05059  \u001b[39m | \u001b[39m4.454    \u001b[39m | \u001b[39m190.4    \u001b[39m |\n| \u001b[39m46       \u001b[39m | \u001b[39m0.8685   \u001b[39m | \u001b[39m0.06329  \u001b[39m | \u001b[39m5.085    \u001b[39m | \u001b[39m191.2    \u001b[39m |\n| \u001b[39m47       \u001b[39m | \u001b[39m0.8425   \u001b[39m | \u001b[39m0.2721   \u001b[39m | \u001b[39m4.899    \u001b[39m | \u001b[39m51.19    \u001b[39m |\n| \u001b[39m48       \u001b[39m | \u001b[39m0.8805   \u001b[39m | \u001b[39m0.1566   \u001b[39m | \u001b[39m12.15    \u001b[39m | \u001b[39m190.0    \u001b[39m |\n| \u001b[39m49       \u001b[39m | \u001b[39m0.8672   \u001b[39m | \u001b[39m0.07414  \u001b[39m | \u001b[39m5.731    \u001b[39m | \u001b[39m191.6    \u001b[39m |\n| \u001b[39m50       \u001b[39m | \u001b[39m0.8695   \u001b[39m | \u001b[39m0.08126  \u001b[39m | \u001b[39m19.3     \u001b[39m | \u001b[39m140.8    \u001b[39m |\n| \u001b[39m51       \u001b[39m | \u001b[39m0.8819   \u001b[39m | \u001b[39m0.2305   \u001b[39m | \u001b[39m13.38    \u001b[39m | \u001b[39m153.2    \u001b[39m |\n| \u001b[39m52       \u001b[39m | \u001b[39m0.8615   \u001b[39m | \u001b[39m0.29     \u001b[39m | \u001b[39m18.76    \u001b[39m | \u001b[39m25.41    \u001b[39m |\n| \u001b[39m53       \u001b[39m | \u001b[39m0.7998   \u001b[39m | \u001b[39m0.03976  \u001b[39m | \u001b[39m19.1     \u001b[39m | \u001b[39m22.12    \u001b[39m |\n| \u001b[39m54       \u001b[39m | \u001b[39m0.8846   \u001b[39m | \u001b[39m0.09123  \u001b[39m | \u001b[39m6.267    \u001b[39m | \u001b[39m191.3    \u001b[39m |\n| \u001b[39m55       \u001b[39m | \u001b[39m0.8729   \u001b[39m | \u001b[39m0.06353  \u001b[39m | \u001b[39m7.637    \u001b[39m | \u001b[39m178.6    \u001b[39m |\n=============================================================\nHyperparameters tuning time: 847.862 seconds\nMeilleurs hyperparamètres : {'learning_rate': 0.2521515193606912, 'max_depth': 5, 'n_estimators': 191}\nTraining time: 8.481 seconds\nTest (prediction) time: 0.062 seconds\nRapport de classification :\n               precision    recall  f1-score   support\n\n       blues       0.92      0.90      0.91       300\n   classical       0.93      0.97      0.95       299\n     country       0.83      0.89      0.86       299\n       disco       0.87      0.91      0.89       300\n      hiphop       0.92      0.88      0.90       299\n        jazz       0.91      0.91      0.91       300\n       metal       0.95      0.94      0.94       300\n         pop       0.95      0.87      0.91       300\n      reggae       0.90      0.90      0.90       300\n        rock       0.86      0.83      0.85       300\n\n    accuracy                           0.90      2997\n   macro avg       0.90      0.90      0.90      2997\nweighted avg       0.90      0.90      0.90      2997\n\nMatrice de confusion :\n [[271   1   6   3   2   4   3   0   6   4]\n [  0 291   4   0   0   3   0   1   0   0]\n [  7   1 267   3   1   9   0   1   4   6]\n [  3   0   3 272   6   0   3   2   2   9]\n [  2   1   2   7 263   3   5   3  12   1]\n [  2  10   8   0   0 274   0   0   2   4]\n [  1   1   2   3   2   0 283   0   1   7]\n [  0   2   7  11   8   1   0 261   2   8]\n [  3   2   4   5   2   4   0   7 271   2]\n [  6   3  18  10   2   4   5   0   2 250]]\n","output_type":"stream"}],"execution_count":29}]}